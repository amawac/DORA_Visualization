{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3627ba8",
   "metadata": {},
   "source": [
    "# RUN THE BOTTOM CHUNK OF CODE AS SOON AS YOU OPEN THIS "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9e3f71",
   "metadata": {},
   "source": [
    "Scroll to the bottom and run the two large cells that say HEY RUN THIS and HEY RUN THIS 2!!!\n",
    "\n",
    "Sorry this is painful it has to do with the fact that juypter notebooks can't call things like plotting in line (matplotlib) or generating windows(cv2) from a .py  they need to be defined in the notebook as as far as I know. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150688fe",
   "metadata": {},
   "source": [
    "## common troubleshooting solutions:\n",
    "\n",
    "1. make sure your file paths use these slashes / and end with a / \n",
    "2. make sure you run the two blocks of code at the bottom\n",
    "3. are you in the righ file paths?\n",
    "4. is your info file the same name as your tif file?\n",
    "\n",
    "### NOTE: This is a 'cleaned' copy of the OMM_Analysis from the lab's github I made from running data from ONI using TIFF files. If you have something  else, this is not for you.   \n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6e02234",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('D:/Amanda/OMM_Analysis/OMM_Analysis/sma/') #if you are not amanda, change to your sma file path (found in zipfile downloaded from github)\n",
    "\n",
    "from ffpdax import ffp_dax\n",
    "from ffptif import ffp_tif\n",
    "\n",
    "analysisPath='D:/Amanda/OMM_Analysis/OMM_Analysis/DATA/20220331_Proflavine_Base2DORBIT_exp8/IB_10hz_10laser_10uM_on/pos_0/' \n",
    "\n",
    "xmlName='ORBIT_Analysis_Settings'\n",
    "\n",
    "analysisName='Proflavine_Base2DORBIT_exp8_IB_10hz_10laser_10uM_on_posXY0_channels_t0_posZ0'\n",
    "\n",
    "xmlFilename=analysisPath+xmlName\n",
    "filename=analysisPath+analysisName\n",
    "#ffp_tif(filename,xmlFilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77b7760b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "newpath = filename+'trcsv'\n",
    "if not os.path.exists(newpath):\n",
    "    os.makedirs(newpath)    #makes a new folder in with same name as filename but ending in trcsv\n",
    "    \n",
    "from tr2csv import tr_2csv\n",
    "tr_2csv(filename)           #Generates CSV file from .tr files      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be8d4a4",
   "metadata": {},
   "source": [
    "## 2D histogram stuff\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fb6b420",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of peaks\n",
      "42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "histInfoName=filename+'trdir/histpar' # opens the infromation file\n",
    "histInfoFile = open(histInfoName+'.info','rb')\n",
    "histInfo=np.fromfile(histInfoFile,dtype='int32')\n",
    "histInfoFile.close()\n",
    "print(\"Number of peaks\")\n",
    "print(histInfo[3])\n",
    "histInfo[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc6b5fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57.0\n"
     ]
    }
   ],
   "source": [
    "print(16416/16/18) # i think this is just to make sure it runs, im scared to remove it lol\n",
    "\n",
    "#display settings for tracjectories\n",
    "histPerCol=7\n",
    "histPerRow=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4a3f5b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  41    0 1000]\n",
      "[  41    0 1000]\n",
      "[  40    0 1000]\n",
      "[  40    0 1000]\n",
      "[  39    0 1000]\n",
      "[  39    0 1000]\n",
      "[  30    0 1000]\n",
      "[  30    0 1000]\n",
      "[  31    0 1000]\n",
      "[  31    0 1000]\n",
      "[  24    0 1000]\n",
      "[  24    0 1000]\n",
      "[  35    0 1000]\n",
      "[  35    0 1000]\n",
      "pk, t1 ,t2\n",
      "[[  41    0 1000]\n",
      " [  41    0 1000]\n",
      " [  40    0 1000]\n",
      " [  40    0 1000]\n",
      " [  39    0 1000]\n",
      " [  39    0 1000]\n",
      " [  30    0 1000]\n",
      " [  30    0 1000]\n",
      " [  31    0 1000]\n",
      " [  31    0 1000]\n",
      " [  24    0 1000]\n",
      " [  24    0 1000]\n",
      " [  35    0 1000]\n",
      " [  35    0 1000]]\n"
     ]
    }
   ],
   "source": [
    "#when you run this, you should get a pop up window. check your windows bar at the bottom of the deskstop  \n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import argparse\n",
    "import cv2\n",
    "\n",
    "\n",
    "[refptnp,refsc,refcol,sum_of_rows, out]=disp_hist(filename,histPerCol,histPerRow) #change for dax\n",
    "print('pk, t1 ,t2')\n",
    "print(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a388159",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remeber python indexs from 0 so if you want your first selection to be the peak you analyze pick 0\n",
    "#also the peaks go in paired sets, the first two selections will be \"peak 0\"\n",
    "\n",
    "chosenpk=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8bc7d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peak: 00041\n",
      "Start: 0\n",
      "End: 1000\n"
     ]
    }
   ],
   "source": [
    "pk=str(out[chosenpk*2,0]).zfill(5)\n",
    "frStart=out[chosenpk*2,1]\n",
    "frEnd=out[((chosenpk*2)+1),2] \n",
    "print(\"Peak: \"+pk)\n",
    "print(\"Start: \"+str(frStart))\n",
    "print(\"End: \"+str(frEnd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "516947f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#manual\n",
    "pk=str('00038')\n",
    "frStart=0\n",
    "frEnd=999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "219c5bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/Amanda/OMM_Analysis/OMM_Analysis/DATA/20220331_Proflavine_Base2DORBIT_exp8/IB_10hz_10laser_10uM_on/pos_0/Proflavine_Base2DORBIT_exp8_IB_10hz_10laser_10uM_on_posXY0_channels_t0_posZ0trcsv/00041.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "title='Exp 8 - 10uM on - Peak ' +pk\n",
    "\n",
    "csvpath=filename+'trcsv/'\n",
    "\n",
    "\n",
    "csvnum=csvpath+pk+'.csv'\n",
    "\n",
    "print(csvnum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514e28d6",
   "metadata": {},
   "source": [
    "## Graphing Paramaters below\n",
    "#if anyone knows how to code this so allow us to save stuff in the folder that'd be super cool\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "223c6a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename: D:/Amanda/OMM_Analysis/OMM_Analysis/DATA/20220331_Proflavine_Base2DORBIT_exp8/IB_10hz_10laser_10uM_on/pos_0/Proflavine_Base2DORBIT_exp8_IB_10hz_10laser_10uM_on_posXY0_channels_t0_posZ0trcsv/00041.csv    |  pixel_size: 117  |  time_step: 100\n",
      "frame_start: 0  |    frame_end: 1000  |  bin_size: 20\n",
      "processing: none  |  plot_type: grid  |  title: Exp 8 - 10uM on - Peak 00041\n",
      "X_axis_label: x (nm)  |  Y_axis_label: y (nm)  |  Z_axis_label: Time (ms)\n",
      "columns: 7 | frames_per_plot: 195\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17816\\3891744933.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m \u001b[0mDORA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36mDORA\u001b[1;34m(file_name, pixel_size, time_step, frame_start, frame_end, auto_frame_end, find_center_coordinates, bin_size, display_center, processing, plot_type, title, x_axis_label, y_axis_label, z_axis_label, unit, rad_filter_type_lower, rad_filter_type_upper, z_up, z_down, dist_low, dist_high, frames_per_plot, columns, pixel_min, pixel_max, nm_min, nm_max, axis_increment_pixel, axis_increment_nm, fig_size_x, fig_size_y, frame_speed, tail_length, graph_style, save_plot, save_filtered_table)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\origami\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   5037\u001b[0m             \u001b[1;31m# GH#44051 exclude bool, which would return a 2d ndarray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5038\u001b[0m             \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast_scalar_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn_float\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5039\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mgetitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5041\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "##############################################Initial required parameters    [COMEBack]\n",
    "'file_name': csvnum,\n",
    "'pixel_size': 117, # in nanometers\n",
    "'time_step': 100, # miliseconds per frame in trajectory movie\n",
    "'frame_start': frStart, # enter 0 to start from beginning of dataset\n",
    "'frame_end': frEnd, # enter -1 to end at the last value of the data set\n",
    "'auto_frame_end': 'yes', # yes to cut off all values after first 0,0 = x,y\n",
    "'find_center_coordinates': 'yes', # 'yes' for first run, 'no' after center has been determined\n",
    "##############################################Secondary required parameters  \n",
    "'plot_type': \"grid\",\n",
    "        #Graphing options: \n",
    "            #2D: Colorful 2D visulization of the rotor from above\n",
    "            #3D: 2D plot but time is an axis\n",
    "            #grid: a grid of little snippets of the data\n",
    "            \n",
    "            #angular: angle vs time, but it's not cummulative and resets at 360 to 0 (Claire)\n",
    "            #angular_continuous: Claire's Calculation of a cummulative angle\n",
    "            #radius_filter: Demarcate the sus data points that will be eliminated from calculations\n",
    "            #find_sus_angle_CR: Indicate sus angles within angular_continuous by Claire\n",
    "            #find_sus_angle_JW: Indicate sus angles within angular_continuous by Jerry \n",
    "            #angular_continuous_filtered: Angular Continuous recalculated with sus points filtered. Sus skips indicated.  \n",
    "            \n",
    "            #Experiment tailored:\n",
    "                #basal1: outmoded \n",
    "                #basal2: outmoded \n",
    "                #basal3: Angular Continuous but for [COMEBACK]\n",
    "    \n",
    "            #interactive: Interactive graph\n",
    "            #animated: animated trajectory in notebook\n",
    "            #HTML: Animated trajectory in a new window. May run better \n",
    "'bin_size': 20, # bin size for downsample/filter processing\n",
    "'display_center': \"yes\", # \"yes\" enabbles center display of center coordinates if 2D or Find sus angle\n",
    "'processing': \"none\", # enter downsample, filter, or none\n",
    "'unit': \"nm\",  # enter pixel or nm \n",
    "####################################################Labeling parameters \n",
    "'title': title,\n",
    "'x_axis_label': \"x (nm)\",\n",
    "'y_axis_label': \"y (nm)\",\n",
    "'z_axis_label': \"Time (ms)\",\n",
    "####################################################Formatting parameters for 'radius_filter'\n",
    "'rad_filter_type_lower': 'nm',   #enter 'zscore' or 'nm' for choice \n",
    "'rad_filter_type_upper': 'zscore',   #enter 'zscore' or 'nm' for choice \n",
    "'z_up': 3, # enter an upper bound for z score. \n",
    "'z_down': -3, # enter a lower bound for z score\n",
    "'dist_low': 30, # lower bound for ABS of Radius filter\n",
    "'dist_high': 70, # upper bound for ABS of Radius filter\n",
    "####################################################Formatting parameters 'grid' plot\n",
    "'frames_per_plot': 195, #refers to grid plot\n",
    "'columns': 7,# columns of plots (grid plot)\n",
    "####################################################Formatting parameters 'animation' plot\n",
    "'frame_speed': 20, # for animation only (ms)\n",
    "'tail_length': 50, # for animation only\n",
    "####################################################Formatting parameters for 'angular_continuous_filtered' plot\n",
    "'graph_style': 'line', #enter 'line' or 'scatter' for a line graph or a scatter plot. Line plot makes up points when hovered\n",
    "################################################### #Formatting parameters all plots  \n",
    "'pixel_min': -0.75, # setting min/max axis range (pixel)\n",
    "'pixel_max': 0.75,\n",
    "'axis_increment_pixel': 7, #change axis increments for nicely fitting tick marks (pixel)\n",
    "'nm_min': -150, # setting min/max axis range (nm)\n",
    "'nm_max': 150,\n",
    "'axis_increment_nm': 7, #change axis increments for nicely fitting tick marks (nm)\n",
    "'fig_size_x': 40, #adjust display parameters for graphs to fit nicely, mostly used for 'grid' plot \n",
    "'fig_size_y': 40,\n",
    "####################################################Save figures and Data Table\n",
    "'save_plot': 'no',\n",
    "'save_filtered_table': 'no', # 'yes' saves final data table \"data\" as a csv file\n",
    "} \n",
    "\n",
    "\n",
    "DORA(**parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089fdd81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a33327",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b1d7752",
   "metadata": {},
   "source": [
    "# HEY! RUN THIS: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ea421c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def disp_hist(file,perCol,perRow):\n",
    "\n",
    "    \n",
    "    #Get file paths\n",
    "    sets=file+'trdir/histsets'\n",
    "    filename=file+'trdir/hist2d'\n",
    "    infor=file+'trdir/histpar'\n",
    "    \n",
    "    #open files\n",
    "    fileptr = open(filename+'.stack','rb')\n",
    "    fileptrSets = open(sets+'.list','rb')\n",
    "    fileptrInfo = open(infor+'.info','rb')\n",
    "    \n",
    "\n",
    "    #Get Infor from files \n",
    "    frame = np.fromfile(fileptr,dtype='int32')\n",
    "    histlist=np.fromfile(fileptrSets,dtype='int32')\n",
    "    histinfo=np.fromfile(fileptrInfo,dtype='int32')\n",
    "    histsearch=np.reshape(histlist,[len(histlist)//3,3])\n",
    "    #print(frame.shape)\n",
    "    #print(histlist.shape)\n",
    "    #print(histinfo.shape)\n",
    "\n",
    "    histnum=histinfo[3]  #number of histograms\n",
    "    histrow=int(histnum//perCol) #number of histograms / number of histograms per col to give number per row \n",
    "    \n",
    "    res=histinfo[0]   #get the 'res' as defined in 2D hist this is the size of the histogram 30x30\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    #Openining the Histogram and making an Image. \n",
    "    fileptr.seek(0) #Get the first frame \n",
    "\n",
    "    result = Image.new('F', (histrow*res,perCol*res)) #make a new image of correct size \n",
    "    for j in range (0,histrow):    \n",
    "        for i in range (0,perCol):\n",
    "        #print((i+(j*histpercol)))\n",
    "            fileptr.seek((i+(j*perCol))*res*res*4)  #open frame poisiton x resolution *32/8 (8 bit vs 32 bit)\n",
    "            frame2 = np.fromfile(fileptr,dtype='int32',count=res*res)\n",
    "            frame2 = np.reshape(frame2,[res,res])\n",
    "            frame2 = np.transpose(frame2)\n",
    "            frame2 = np.rot90(np.rot90(np.rot90(frame2)))\n",
    "            frame2=frame2\n",
    "            im2 =Image.fromarray(frame2)\n",
    "        #print(i)\n",
    "            result.paste(im2, box=((j*res),(i*res))) #load each histogram into the total histogram image. \n",
    "       \n",
    "    \n",
    "   \n",
    "\n",
    "    img = np.array(result) \n",
    "\n",
    "    #result.show(result)\n",
    "    avgnonzero = img[np.nonzero(img)].mean() #this might be bad practice \n",
    "    img=np.array((img/avgnonzero)*255).astype('uint8')#but here i am sclaing my image based on avg non zero to gray scale \n",
    "                                                        # This is only for display and it works fairly well but may be something that we want to return to. \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    grayImage = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)  #Converts image to gray scale\n",
    "    heatmap = cv2.applyColorMap(grayImage, cv2.COLORMAP_MAGMA)  #converst grey scale to color map magma \n",
    "    \n",
    "    refPt = []\n",
    "    \n",
    "    def click_event(event, x, y, flags, param):\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            #print(x+(k*histperrow*30),\",\",y)\n",
    "            imgpkdisp=[((x+(k*perRow*30))//30*perCol),y//30] #Converting X and y of click to position on histogram as a grid. K s frame number. Scale by 30 because of size of histogram. \n",
    "            imgpkdisp=sum(imgpkdisp)  # This is the exact histogram number. based off frame, and which position\n",
    "            imgpkdisp=histsearch[imgpkdisp] # now we use that info to find the hisgram in the  info file \n",
    "            imgpkdisp=str(imgpkdisp)\n",
    "            print(imgpkdisp)\n",
    "            refPt.append([x+(k*perRow*30),y]) #This stores the histograms selected. \n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            strXY = str(x+(k*perRow*30) )+\", \"+str(y)\n",
    "            cv2.putText(imgcrop, imgpkdisp, (x,y), font, 0.5, (255,0,0), 2) #Draw coordinates on image. \n",
    "            cv2.imshow('2D Histogram [PK# t1 t2]',imgcrop)\n",
    "    \n",
    "    savePt=[]\n",
    "    testvar=0\n",
    "    t=img.size//((perCol*30)*perRow*30)\n",
    "    \n",
    "    k=0\n",
    "    \n",
    "    #Load in frames for searching\n",
    "    while k < t:\n",
    "        imgcrop=heatmap[0:(perCol*30),k*perRow*30:(k+1)*30*perRow]  #Display each frame as a heat map. \n",
    "        cv2.imshow('2D Histogram [PK# t1 t2]',imgcrop )\n",
    "        cv2.namedWindow('2D Histogram [PK# t1 t2]')\n",
    "        cv2.setMouseCallback('2D Histogram [PK# t1 t2]', click_event)\n",
    "        key=cv2.waitKey(0)\n",
    "        if key == 27: #if escape key break the loop\n",
    "            break\n",
    "        elif key==98:  # if b go backwards\n",
    "            if k == 0:\n",
    "                k=k\n",
    "            else:\n",
    "                k=k-1  # any other key go forward\n",
    "        else:\n",
    "            k=k+1\n",
    "        \n",
    "   # for k in range (0,t):\n",
    "       # print(k)\n",
    "       # imgcrop=heatmap[0:(perCol*30),k*perRow*30:(k+1)*30*perRow]\n",
    "       # cv2.imshow('heatmap',imgcrop )\n",
    "       # cv2.namedWindow('heatmap')\n",
    "       # cv2.setMouseCallback(\"heatmap\", click_event)\n",
    "       # key=cv2.waitKey(0)\n",
    "        #if key == 27:\n",
    "        #    break\n",
    "        #elif key == 98:\n",
    "            #print(k)\n",
    "        \n",
    "        \n",
    "            \n",
    "    cv2.destroyAllWindows()\n",
    "    refptnp=np.array(refPt)  #stored histogram positions\n",
    "    #print(refptnp)\n",
    "    refsc=refptnp//30     # scale to histogram number per frame\n",
    "    refcol=refsc*[perCol,1]  # Scale to be histogram number on right frame \n",
    "    sum_of_rows = np.sum(refcol, axis = 1)  #sum to get historgram number\n",
    "    out=histsearch[sum_of_rows] #search  histogram info to get pk# and T1 T2. \n",
    "    return refptnp , refsc , refcol ,sum_of_rows , out   #Return Relevant vars. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155a56a8",
   "metadata": {},
   "source": [
    "# HEY! RUN THIS 2: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1ee264d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename: 00086.csv    |  pixel_size: 154  |  time_step: 20\n",
      "frame_start: 0  |    frame_end: -1  |  bin_size: 20\n",
      "processing: none  |  plot_type: basal3  |  title: RecBCD.csv\n",
      "X_axis_label: x (nm)  |  Y_axis_label: y (nm)  |  Z_axis_label: Time (ms)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '00086.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36mDORA\u001b[1;34m(file_name, pixel_size, time_step, frame_start, frame_end, auto_frame_end, find_center_coordinates, bin_size, display_center, processing, plot_type, title, x_axis_label, y_axis_label, z_axis_label, unit, rad_filter_type_lower, rad_filter_type_upper, z_up, z_down, dist_low, dist_high, frames_per_plot, columns, pixel_min, pixel_max, nm_min, nm_max, axis_increment_pixel, axis_increment_nm, fig_size_x, fig_size_y, frame_speed, tail_length, graph_style, save_plot, save_filtered_table)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\origami\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\origami\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 680\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    681\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\origami\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\origami\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    931\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\origami\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[1;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m             \u001b[1;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[0;32m   1218\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\origami\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    787\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    790\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '00086.csv'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\"\"\"\n",
    "4.4.2022\n",
    "\n",
    "@author: Jerry Wu + Claire Rickets\n",
    "\n",
    "Hi Team, \n",
    "\n",
    "Below is the code that will take Ryan's .tr files and process them into various visualization forms. \n",
    "\n",
    "As a reminder the work flow is as follows:\n",
    "\n",
    "Workflow step 1. Run code with ['find_center_coordinates': 'yes' ], AND #Initial required parameters filled out accordingly\n",
    "    This generates the center guess which will be used by the next run to generate graphs.\n",
    "Worflow step 2. Run code with ['find_center_coordinates': 'no' ], AND input the 'plot_type' you would like to use \n",
    "\n",
    "For any questions feel free to call at 914-806-1369 or email at jdw010@ucsd.edu\n",
    "\n",
    "Features of interest\n",
    "1. Plots:\n",
    "        - To generate the circular 2D plot of the trajectory, use 'plot_type': \"2D\",\n",
    "        - To scope which points are questionable and thus removed from the below plot, use 'plot_type': \"radius_filter\"\n",
    "        - To generate the continuous angle plot from filterted data, use 'plot_type': 'angular_continuous_filtered',\n",
    "                This plot identifies three types of erroneous data: \n",
    "                    1+2) data above or below distance of statistical (standard devation) boundary set\n",
    "                    3) invalid data from .tr files, which were outputted as (0,0)\n",
    "2. if you want to export variables within the function, the last return in the function is the one to use. \n",
    "        - *********NOTE\n",
    "        - I have set this block to export the variable data which is the final data table of the relevant data. \n",
    "          This causes a non fatal when finding center in Workflow step 1. \n",
    "          This error can be removed by deleting the data after the last return and data as an exported variable. \n",
    "            (         return data <-- this one\n",
    "\n",
    "               data = DORA(**parameters))       <-- this one also          \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from mpl_toolkits.mplot3d.art3d import Line3DCollection \n",
    "from matplotlib import ticker\n",
    "import math\n",
    "from matplotlib import gridspec\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.animation\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import matplotlib.animation as animation\n",
    "from IPython import display\n",
    "import random\n",
    "import itertools\n",
    "from matplotlib.widgets import Slider, Button\n",
    "from IPython.core.display import HTML\n",
    "matplotlib.rcParams['animation.embed_limit'] = 2**128 #allows for large java HTML\n",
    "import mplcursors # Jerry adds way to hover data points in matplotlib rather than plotly\n",
    "import scipy.stats as stats # added to calculate z-score for Radius filtering\n",
    "\n",
    "#affects plot presentation\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "parameters = {\n",
    "##############################################Initial required parameters    [COMEBack]\n",
    "'file_name': '00086.csv',\n",
    "'pixel_size': 154, # in nanometers\n",
    "'time_step': 20, # miliseconds per frame in trajectory movie\n",
    "'frame_start': 0, # enter 0 to start from beginning of dataset\n",
    "'frame_end': -1, # enter -1 to end at the last value of the data set\n",
    "'auto_frame_end': 'yes', # yes to cut off all values after first 0,0 = x,y\n",
    "'find_center_coordinates': 'no', # 'yes' for first run, 'no' after center has been determined\n",
    "##############################################Secondary required parameters  \n",
    "'plot_type': \"basal3\",\n",
    "        #Graphing options: \n",
    "            #2D: Colorful 2D visulization of the rotor from above\n",
    "            #3D: 2D plot but time is an axis\n",
    "            #grid: a grid of little snippets of the data\n",
    "            \n",
    "            #angular: angle vs time, but it's not cummulative and resets at 360 to 0 (Claire)\n",
    "            #angular_continuous: Claire's Calculation of a cummulative angle\n",
    "            #radius_filter: Demarcate the sus data points that will be eliminated from calculations\n",
    "            #find_sus_angle_CR: Indicate sus angles within angular_continuous by Claire\n",
    "            #find_sus_angle_JW: Indicate sus angles within angular_continuous by Jerry \n",
    "            #angular_continuous_filtered: Angular Continuous recalculated with sus points filtered. Sus skips indicated.  \n",
    "            \n",
    "            #Experiment tailored:\n",
    "                #basal1: outmoded \n",
    "                #basal2: outmoded \n",
    "                #basal3: Angular Continuous but for [COMEBACK]\n",
    "    \n",
    "            #interactive: Interactive graph\n",
    "            #animated: animated trajectory in notebook\n",
    "            #HTML: Animated trajectory in a new window. May run better \n",
    "'bin_size': 20, # bin size for downsample/filter processing\n",
    "'display_center': \"yes\", # \"yes\" enabbles center display of center coordinates if 2D or Find sus angle\n",
    "'processing': \"none\", # enter downsample, filter, or none\n",
    "'unit': \"nm\",  # enter pixel or nm \n",
    "####################################################Labeling parameters \n",
    "'title': \"RecBCD.csv\",\n",
    "'x_axis_label': \"x (nm)\",\n",
    "'y_axis_label': \"y (nm)\",\n",
    "'z_axis_label': \"Time (ms)\",\n",
    "####################################################Formatting parameters for 'radius_filter'\n",
    "'rad_filter_type_lower': 'nm',   #enter 'zscore' or 'nm' for choice \n",
    "'rad_filter_type_upper': 'zscore',   #enter 'zscore' or 'nm' for choice \n",
    "'z_up': 3, # enter an upper bound for z score. \n",
    "'z_down': -3, # enter a lower bound for z score\n",
    "'dist_low': 30, # lower bound for ABS of Radius filter\n",
    "'dist_high': 70, # upper bound for ABS of Radius filter\n",
    "####################################################Formatting parameters 'grid' plot\n",
    "'frames_per_plot': 195, #refers to grid plot\n",
    "'columns': 7,# columns of plots (grid plot)\n",
    "####################################################Formatting parameters 'animation' plot\n",
    "'frame_speed': 20, # for animation only (ms)\n",
    "'tail_length': 50, # for animation only\n",
    "####################################################Formatting parameters for 'angular_continuous_filtered' plot\n",
    "'graph_style': 'line', #enter 'line' or 'scatter' for a line graph or a scatter plot. Line plot makes up points when hovered\n",
    "################################################### #Formatting parameters all plots  \n",
    "'pixel_min': -0.75, # setting min/max axis range (pixel)\n",
    "'pixel_max': 0.75,\n",
    "'axis_increment_pixel': 7, #change axis increments for nicely fitting tick marks (pixel)\n",
    "'nm_min': -150, # setting min/max axis range (nm)\n",
    "'nm_max': 150,\n",
    "'axis_increment_nm': 7, #change axis increments for nicely fitting tick marks (nm)\n",
    "'fig_size_x': 40, #adjust display parameters for graphs to fit nicely, mostly used for 'grid' plot \n",
    "'fig_size_y': 40,\n",
    "####################################################Save figures and Data Table\n",
    "'save_plot': 'no',\n",
    "'save_filtered_table': 'yes', # 'yes' saves final data table \"data\" as a csv file\n",
    "} \n",
    "\n",
    "\n",
    "def DORA(file_name,pixel_size,time_step,frame_start,frame_end,auto_frame_end,find_center_coordinates,bin_size,display_center,processing,plot_type,title,x_axis_label,y_axis_label,z_axis_label,unit,rad_filter_type_lower,rad_filter_type_upper,z_up,z_down,dist_low,dist_high, frames_per_plot, columns, pixel_min, pixel_max, nm_min, nm_max,axis_increment_pixel,axis_increment_nm, fig_size_x, fig_size_y, frame_speed, tail_length, graph_style, save_plot, save_filtered_table):\n",
    "       \n",
    "              \n",
    "        print(*['filename:', file_name, '   | ' , 'pixel_size:', pixel_size , ' | ' , 'time_step:', time_step])\n",
    "        \n",
    "        print(*['frame_start:', frame_start,' |   ','frame_end:', frame_end, ' | ', 'bin_size:', bin_size])\n",
    "        \n",
    "        print(*['processing:', processing, ' | ',  'plot_type:', plot_type,' | ' ,'title:', title])\n",
    "        \n",
    "        print(*['X_axis_label:',x_axis_label,' | ',  'Y_axis_label:',y_axis_label ,' | ' ,'Z_axis_label:', z_axis_label])\n",
    "        if plot_type == 'grid':\n",
    "            print(*['columns:', columns, '|', 'frames_per_plot:', frames_per_plot])\n",
    "        if plot_type == 'animated':\n",
    "            print(*['frame_speed:', frame_speed, '|', 'tail_length:', tail_length])\n",
    "        if plot_type == 'radius_filter':\n",
    "            print(*['Radius Filtering Style Lower:', rad_filter_type_lower])\n",
    "            if rad_filter_type_lower == 'zscore':\n",
    "                print(*['Lower Z-Score:', z_down])\n",
    "            else:\n",
    "                print(*['Lower Dist:', dist_low])\n",
    "            print(*['Radius Filtering Style Upper:', rad_filter_type_upper])\n",
    "            if rad_filter_type_upper == 'zscore':\n",
    "                print(*['Upper Z-Score:', z_up])\n",
    "            else:\n",
    "                print(*['Lower Dist:', dist_high])\n",
    "        \n",
    "    \n",
    "        #read data file into a pandas data frame, add an index counter, and label columns\n",
    "#         data = pd.read_csv(file_name, header = None)\n",
    "#         data = data.dropna()\n",
    "#         data['index'] = range(len(data))\n",
    "#         data.columns = ['X position', 'Y position','index']\n",
    "#         data=data[['index','X position','Y position']\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        #I will analyze the raw data from Ryan's code as pre_data and then covert that into two separate parts \n",
    "        #1) (data) the data formatted as arrays to be graphed [necessary numbers only]\n",
    "        #2) (data_back) the data formated as a Dataframe for record keeping [NaN placed where sus value lies] \n",
    "        pre_data = pd.read_csv(file_name, header = None) # read the csv file intended \n",
    "#         pre_data = pre_data.dropna()  # drop all NaN values?\n",
    "        pre_data['index'] = range(len(pre_data)) # create an array increasing in steps of\n",
    "        pre_data.columns = ['X position', 'Y position','index'] # label the columns\n",
    "        pre_data = pre_data.iloc[:,[2,0,1]] # reorganize the columns \n",
    "        ind_invalid_reading = pre_data['X position']== 0 # create a boolean array of where 1s are when x position is 0 or invalid\n",
    "        ## this is bc Ryan's code exports invalid readings as (0,0)\n",
    "        \n",
    "        if auto_frame_end == 'yes':\n",
    "            find_first_0 = (pre_data[\"X position\"] == 0) & (pre_data[\"Y position\"] == 0)\n",
    "            pre_x = pre_data[\"X position\"].copy()\n",
    "            pre_x = pre_data[find_first_0]\n",
    "            my_first_0 = pre_x.index[0]\n",
    "            frame_end = my_first_0\n",
    "\n",
    "        \n",
    "        #SEPARATE data into front and back end (front==graphing ; back == tables)\n",
    "        data = pre_data[~ind_invalid_reading].copy() # if the index is not invalid (or valid) keep it and store in data\n",
    "        data_back = pre_data[ind_invalid_reading].copy() # section the pre data for all the invalid values\n",
    "        \n",
    "        \n",
    "        #in data back develop a time colomn\n",
    "        data_back['Time (ms)'] = data_back['index']*time_step\n",
    "        \n",
    "        data_back['X position'] = np.nan #set all target x positions to NaN, if the reading was sus\n",
    "        data_back['Y position'] = np.nan # set all target y positions to NaN, if the reading was sus \n",
    "        data_back['Sus Type'] = 'Invalid Reading'\n",
    "        \n",
    "        \n",
    "            \n",
    "        ####################################### CENTERING ALGORITHM ###############################################\n",
    "        if find_center_coordinates == 'yes':\n",
    "            #establish empty lists\n",
    "            ave_y = []\n",
    "            ave_x = []\n",
    "            stand = []\n",
    "            \n",
    "            #find uniform guesses in range of max and min unaltered data values for y position\n",
    "            #THE NUMBER OF UNIFORM GUESSES IS CURRENTLY HARD CODED AT 50 FOR X AND Y, CULMULITIVE 2,500\n",
    "            guess_y = np.linspace(data.iloc[frame_start:frame_end,2].max(), data.iloc[ frame_start:frame_end,2].min(), 50)\n",
    "            #put into list\n",
    "            guess_y = guess_y.tolist()\n",
    "            # find guesses for x position\n",
    "            guess_x =np.linspace(data.iloc[frame_start:frame_end,1].max(), data.iloc[frame_start:frame_end,1].min(), 50)\n",
    "            guess_x = guess_x.tolist()\n",
    "            \n",
    "            \n",
    "\n",
    "            #permute each x and y center guess together to create 10,000 unique center guesses\n",
    "            center_guesses = list(itertools.product(guess_x, guess_y))\n",
    "            # store center guesses in dataframe\n",
    "            c = pd.DataFrame(center_guesses, columns = ['X','Y'])\n",
    "            # set up list to store average distances (radius) of circular trajectory path\n",
    "            ave_distance = []\n",
    "            # set up list to store standard deviation of distances to each point in the trajectory\n",
    "            stand = []\n",
    "            j = 0\n",
    "            for j in range(len(c)): # chnage to range(len(c))\n",
    "                # find the distance between each point in a dataframe against guess[i]\n",
    "                distance = np.power(((data[\"X position\"]- c['X'][j])**2 + (data[\"Y position\"]- c['Y'][j])**2),0.5)\n",
    "                # store distances in a dataframe\n",
    "                d = pd.DataFrame(distance, columns = ['distance'])\n",
    "                # find average of distances (this would be the radius)\n",
    "                ave_d = d['distance'].mean(axis = 0)\n",
    "                # store all average distances from each guess[i] distance dataframes into list\n",
    "                ave_distance.append(ave_d)\n",
    "                # find standard deviation of center distance from each point in trajectory for each guess[i]\n",
    "                std = d['distance'].std(axis = 0)\n",
    "                # store each standard deviation in a list  \n",
    "                stand.append(std)\n",
    "\n",
    "                j += 1\n",
    "            # put radius and std lists in a dataframe    \n",
    "            c['average_distance'] = ave_distance\n",
    "            c['std'] = stand\n",
    "          \n",
    "\n",
    "            # this block finds the row with the lowest std, the corresponding radius and x,y coordinates for the center\n",
    "            # want to return row with lowest std\n",
    "            target_row = c['std'].idxmin()\n",
    "            # x center guess with lowest std\n",
    "            center_x = c.loc[target_row,'X']\n",
    "            # y center guess with lowest std\n",
    "            center_y = c.loc[target_row,'Y']\n",
    "            #radius of trajectory\n",
    "            dist = c.loc[target_row,'average_distance']\n",
    "\n",
    " \n",
    "            # Our regularly scheduled 2D graphing program\n",
    "            fig = plt.figure(figsize=(6,6), dpi=100)\n",
    "            ax = fig.add_subplot(111)#121 # 1X1 grid plot 1, subplot(222) would be 2X2 grid plot 2, (223)--> 2X2 plot 3\n",
    "\n",
    "            #color bar color scheme assignment, graph type, colorbar size and alignment\n",
    "            colors = cm.viridis(np.linspace(0, 1, len(data.iloc[frame_start:frame_end,1])))\n",
    "            ax.scatter(data.iloc[frame_start:frame_end,1], data.iloc[frame_start:frame_end,2],c= colors, alpha = 0.7)\n",
    "            \n",
    "            # add a red dot to indicate center of trajectory\n",
    "            ax.scatter(center_x, center_y, color = 'red')\n",
    "            plt.text(x = center_x +0.02, y = center_y +0.02, s = 'algorithm centering')\n",
    "\n",
    "            # add a circle with center at our best guess and radius derived from our best guess \n",
    "            circle = plt.Circle((center_x, center_y), dist, color='r', fill=False)\n",
    "            ax.add_patch(circle)\n",
    "            \n",
    "            #Colorbar parameters below if we want one in the future\n",
    "\n",
    "            # cbar = plt.colorbar(p, label= 'time' ,                asdfshrink= .82) #\n",
    "\n",
    "            # #setting the ticks on the colorbar to span the length of the time column with 6 increments\n",
    "            # cbar.set_ticks([0, 0.2, 0.4, 0.6, 0.8, 1]) \n",
    "\n",
    "            # tix = np.linspace(0,len(data),6, dtype = int) # forces colorbar to show time in integers\n",
    "            # tix_c = tix*20\n",
    "            # cbar.set_ticklabels(tix_c) \n",
    "            \n",
    "            plt.axis('square') #INTEGRAL to maintaining aspect ratio\n",
    "            plt.xticks(rotation=45)\n",
    "            ax.set_xlabel('X position (unaltered)', fontweight = 'bold', fontsize = 14)\n",
    "            ax.set_ylabel('Y position (unaltered)', fontweight = 'bold', fontsize = 14)\n",
    "\n",
    "            # plot title and font configurations\n",
    "            plt.title('Algorithm Center Guess' , fontweight = 'bold', fontsize = 16)\n",
    "            plt.show()\n",
    "            \n",
    "            \n",
    "            #below is the key to maintaining the value of the center variable once the user satisfaction is achieved\n",
    "            global center\n",
    "            \n",
    "            center =(center_x,center_y)\n",
    "            \n",
    "            print('The center is {0}'.format(center))\n",
    "            print('If the center is satisfactory, change the find_center_coordinates parameter to no')\n",
    "            print('If the center is unsatisfactory, adjust the frame_start and frame_end parameters and try again')\n",
    "            \n",
    "            return\n",
    "        \n",
    "        \n",
    "        print('end') \n",
    "            \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        ## DATA NORMILIZATION AND UNIT ASSIGNMENT ##\n",
    "\n",
    "        # find the average of X and Y column respectively\n",
    "        ave = data.mean(axis=0)\n",
    "        \n",
    "\n",
    "        #substract averages from each column to find displacement, store into new columns\n",
    "        data[\"X displacement (pixels)\"] = data['X position'] - center[0]\n",
    "        data[\"Y displacement (pixels)\"] = data['Y position'] - center[1]\n",
    "        # mutiply pixel displacement columns by scaler to find nm displacement, store in new columns\n",
    "        data[\"X displacement (nm)\"] = data['X displacement (pixels)']*pixel_size\n",
    "        data[\"Y displacement (nm)\"]= data['Y displacement (pixels)']*pixel_size\n",
    "        # multiply the index counter column by time_step to make a time step column, store into new column \n",
    "        data[\"Time (ms)\"] = data['index']*time_step\n",
    "        # drop all NaN values *not a number\n",
    "        data = data.dropna() \n",
    "        #drop NAN try to conserve time (what if we have NAN in x and not in Y? need to drop the whole row)\n",
    "        \n",
    "        \n",
    "        print('end1')\n",
    "        \n",
    "        ############################Recalculation of center using distance forumla -- Jerry\n",
    "        #Radius Calculation from distance formula\n",
    "        data['Radius (nm)'] = np.power(((data[\"X displacement (nm)\"])**2 + (data[\"Y displacement (nm)\"])**2),0.5)\n",
    "        \n",
    "        #Z score calculation\n",
    "        data['z-score Rad'] = stats.zscore(data[\"Radius (nm)\"])\n",
    "        \n",
    "        #Angle Calculation\n",
    "        \n",
    "            #Radian to degree conversion factor\n",
    "        r2d = 180/np.pi\n",
    "            \n",
    "            #Take Arc Tan function of x and y coord to get radius. Arctan 2 makes Quad 3 and 4 negative. \n",
    "        data['Angle'] = -np.arctan2(data['Y displacement (nm)'],data['X displacement (nm)'])*r2d\n",
    "            \n",
    "            #Make all Theta values positive equivalents\n",
    "        data.loc[data.Angle < 0, ['Angle']] += 360\n",
    "            \n",
    "\n",
    "        \n",
    "        ## PROCESSING BLOCK ##\n",
    "        print('end3')\n",
    "\n",
    "            \n",
    "        ##Simple Moving Average or \"filter\" dataframe:\n",
    "        ma = pd.DataFrame(data.iloc[:,0],columns=['index'])\n",
    "\n",
    "        window = bin_size\n",
    "        #Built in simple moving average function is applied to normal data and stored in dataframe \"ma\"\n",
    "        ma['X movement' ] = data.iloc[:,1].rolling(window=window).mean()\n",
    "        ma['Y movement'] = data.iloc[:,2].rolling(window=window).mean()\n",
    "        ma['X displacement (pixels)'] = data.iloc[:,3].rolling(window=window).mean()\n",
    "        ma['Y displacement (pixels)'] = data.iloc[:,4].rolling(window=window).mean()\n",
    "        ma['X displacement (nm)'] = data.iloc[:,5].rolling(window=window).mean()\n",
    "        ma['Y displacement (nm)'] = data.iloc[:,6].rolling(window=window).mean()\n",
    "        ma['Time (ms)'] = data.iloc[:,7].rolling(window=window).mean()\n",
    "\n",
    "        #This block delets the null spaces in the new dataframe and realigns the data\n",
    "        ma = ma.apply (pd.to_numeric, errors='coerce')\n",
    "        ma = ma.dropna()\n",
    "        ma = ma.reset_index(drop=True)\n",
    "       \n",
    "        \n",
    "        \n",
    "        \n",
    "        ##Downsampling dataframe:\n",
    "        da=pd.DataFrame(data.iloc[:,:])\n",
    "        #divide original index by sample size and round to nearest whole number to \n",
    "        #achieve new index number underwhich the origial index is stored\n",
    "        u= math.floor(frame_start/bin_size)\n",
    "        v= math.floor(frame_end/bin_size)\n",
    "\n",
    "        #isolate the column (if we print this it will show as a dataframe with 2 cols: indexes and time values)\n",
    "        daT_column=da.iloc[:,7]\n",
    "        daDY_column=da.iloc[:,6]\n",
    "        daDX_column=da.iloc[:,5]\n",
    "        daPY_column=da.iloc[:,4]\n",
    "        daPX_column=da.iloc[:,3]\n",
    "        daI_column=da.iloc[:,0]\n",
    "        daX_column=da.iloc[:,1]\n",
    "        daY_column=da.iloc[:,2]\n",
    "        #We just want the values in the column\n",
    "        daT = daT_column.values\n",
    "        daDY = daDY_column.values\n",
    "        daDX = daDX_column.values\n",
    "        daPY = daPY_column.values\n",
    "        daPX = daPX_column.values\n",
    "        daI = daI_column.values\n",
    "        daX = daX_column.values\n",
    "        daY= daY_column.values\n",
    "        #This function taken from https://stackoverflow.com/questions/10847660/subsampling-averaging-over-a-numpy-array\n",
    "        # allows us to downsample by averages over a set number \n",
    "        #(change 'n' to the number of values you want to average over)\n",
    "        def average(arr, n):\n",
    "            end =  n * int(len(arr)/n)\n",
    "            return np.mean(arr[:end].reshape(-1, n), 1)\n",
    "        #Takes a column from our 'da' dataframe and runs the function over it\n",
    "        #stores the new values in variables as an array (values in a row)\n",
    "\n",
    "        #assigning each new row to a varialble\n",
    "        Time = average(daT,bin_size)\n",
    "        Index = average(daI,bin_size)\n",
    "        Xda = average(daX,bin_size)\n",
    "        Yda = average(daY,bin_size)\n",
    "        Ydisnm = average(daDY,bin_size)\n",
    "        Xdisnm = average(daDX,bin_size)\n",
    "        YdisP = average(daPY,bin_size)\n",
    "        XdisP = average(daPX,bin_size)\n",
    "\n",
    "        #reshaping the data in a 1D column\n",
    "        TimeT = Time[:, np.newaxis]\n",
    "        YdisnmT = Ydisnm[:, np.newaxis]\n",
    "        XdisnmT = Xdisnm[:, np.newaxis]\n",
    "        YdisPT = YdisP[:, np.newaxis]\n",
    "        XdisPT = XdisP[:,np.newaxis]\n",
    "        XdaT = Xda[:, np.newaxis]\n",
    "        YdaT = Yda[:,np.newaxis]\n",
    "        IndexT = Index[:,np.newaxis]\n",
    "        \n",
    "        #stores in a new dataframe 'dsa' for: downsampling average\n",
    "        dsa= pd.DataFrame(IndexT, columns=['index'])\n",
    "        #appending to our data frame\n",
    "        dsa['X movement'] = XdaT\n",
    "        dsa['Y movement'] = YdaT\n",
    "        dsa['X displacement (pixels)'] = XdisPT\n",
    "        dsa['Y displacement (pixels)'] = YdisPT\n",
    "        dsa['X displacement (nm)'] = XdisnmT \n",
    "        dsa['Y displacement (nm)'] = YdisnmT\n",
    "        dsa['Time (ms)'] = TimeT\n",
    "        \n",
    "        print('end2')\n",
    "        \n",
    "        ## FOR MULTIPLE PLOTS\n",
    "        # Function for 2D plot parameters (called when user asks for multiple plots)\n",
    "        # the grid_plot graph type runs best when this function is defined here and is called under plot_type == grid_plot if statement\n",
    "        def do_plot(ax):\n",
    "            #regular graphing parameters for 2D graph (color of scatter, size, shape, tick marks, etc.)\n",
    "            colors = cm.Greens(np.linspace(0, 1, len(z)))\n",
    "            p=ax.scatter(x, y, c=colors)\n",
    "            #fig = plt.figure(figsize=(6,6), dpi=100)\n",
    "            tix = np.linspace(0,len(z),6)\n",
    "            #tix_c = tix*time_step\n",
    "            #cbar2.set_ticklabels(tix_c)\n",
    "            plt.axis('square')\n",
    "            plt.xticks(rotation=45)\n",
    "            if unit == \"pixel\":\n",
    "                ax.set_xlim(pixel_min, pixel_max) \n",
    "                ax.set_ylim(pixel_min, pixel_max)\n",
    "                ax.yaxis.set_major_locator(ticker.LinearLocator(axis_increment_pixel))# change to 5 for increments of .5\n",
    "                ax.xaxis.set_major_locator(ticker.LinearLocator(axis_increment_pixel))\n",
    "                ax.grid()\n",
    "            if unit == \"nm\":\n",
    "                ax.set_xlim(nm_min, nm_max) \n",
    "                ax.set_ylim(nm_min, nm_max)\n",
    "                ax.yaxis.set_major_locator(ticker.LinearLocator(axis_increment_nm))\n",
    "                ax.xaxis.set_major_locator(ticker.LinearLocator(axis_increment_nm))\n",
    "                ax.grid()\n",
    "\n",
    "        \n",
    "        #future processing methods to be added below:\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #DETERMINE PROCESSING AND UNIT TYPE:\n",
    "        #if more processing methods are to be added, an if statement must be\n",
    "        #added with a key word to select that data frame\n",
    "        # \"df\" becomes the variable used in the graphing block below\n",
    "        if processing == \"none\":\n",
    "            df = data\n",
    "        if processing == \"filter\":\n",
    "            df = ma\n",
    "        if processing == \"downsample\":\n",
    "            df = dsa\n",
    "            frame_start = math.floor(frame_start/bin_size)\n",
    "            frame_end = math.floor(frame_end/bin_size)\n",
    "        \n",
    "        \n",
    "        ### DATA PROCESSING FOR COORDINATE CONVERTION ###  CLAIRE CALCULATES ANGLE!\n",
    "        #theta = (0,360) and thetac =(-infinity degrees, infinity degrees)\n",
    "        # radian to degree conversion\n",
    "        r2d = 180/np.pi\n",
    "        #arctan2 is the full unit circle conversion (-pi,pi) as opposed to (-pi/2,pi/2)\n",
    "      \n",
    "        df_filter =pd.DataFrame(df.iloc[:,0])\n",
    "        #find radius\n",
    "        df_filter['radius'] = np.power( np.power(df['Y displacement (pixels)'],2) + np.power(df['X displacement (pixels)'],2), 0.5 )\n",
    "        #find theta arctan2 is the full unit circle conversion (-pi,pi) as opposed to (-pi/2,pi/2)\n",
    "        df_filter['theta'] = -np.arctan2(df['Y displacement (pixels)'],df['X displacement (pixels)'])*r2d \n",
    "        df_filter['Time (ms)'] = df['Time (ms)']\n",
    "        # if r is greater than a certain value, the entire row of this dataframe is stored into the next dataframe\n",
    "        df_theta = df_filter.loc[df_filter['radius'] > 0.167].copy() # we conserve the other columns where the row meets the requirement\n",
    "        # need the .copy() at the end of the line above due to clarity, we want to alter the dataframe to make df_theta, not df_filter\n",
    "        #arctan2 is the full unit circle conversion (-pi,pi) as opposed to (-pi/2,pi/2)\n",
    "        #add 360 onto the 3rd and 4th quadrant values to make range from (0,360)\n",
    "        df_theta.loc[df_theta.theta < 0, ['theta']] += 360#df_theta is our (0,360) dataframe\n",
    "        \n",
    "         \n",
    "        \n",
    "        #make dataframe for angular continuous (base dataframe changes with user preferences)\n",
    "        angularc = pd.DataFrame(df_theta.iloc[:,2]) # df_theta.iloc[:,2] is the (0,360) theta range\n",
    "        angularc.columns = ['theta']\n",
    "        print('end')\n",
    "        #add a row of zeros at the top and reset index\n",
    "        zero_row = pd.DataFrame({'theta': 0}, index=[0])\n",
    "        angularc = pd.concat([zero_row, angularc]).reset_index(drop = True)\n",
    "        \n",
    "        # find displacement between rows (row[i+1]-row[i]) 350- 25 == 325 --> -35\n",
    "        angularc['displacement'] = angularc.diff()# find displcement between rows\n",
    "        angularc= angularc.apply (pd.to_numeric, errors='coerce')\n",
    "        angularc = angularc.dropna() #drop the NANs if there are any\n",
    "        angularc = angularc.reset_index(drop=True) #reset the index\n",
    "        angular_vector = angularc['displacement'].values #store the dataframe into an array\n",
    "        angular_vectorT = angular_vector.T # transpose the array into a row vector\n",
    "        \n",
    "        \n",
    "        #Now we have displacement between rows\n",
    "        # if the displacement between two rows is greater than 180, subtract 360 (we assume the rotor went backward)\n",
    "        # if the displacement between two rows is less than -180, add 360 (we assume the rotor went forward)\n",
    "        # so we edit the displacement to reflect the rotor movement\n",
    "        \n",
    "        angular_vectorT[angular_vectorT >=(180)] -= 360\n",
    "        \n",
    "        angular_vectorT[angular_vectorT <=(-180)] += 360\n",
    "        \n",
    "        #angular_vectorT[sqrt(x**2+(y)**2) < 0.166] = NaN # get this to work\n",
    "        #df['Y displacement (pixels)']**2 + df['X displacement (pixels)']**2\n",
    "        \n",
    "        #store it back in a pandas dataframe\n",
    "        disp = angular_vectorT.T\n",
    "        cont_rotation = pd.DataFrame(disp, columns=['theta displacement correction'])\n",
    "        \n",
    "        # add a row of zeros to the top so we conserve the first row\n",
    "        zero_row = pd.DataFrame({'theta displacement correction': 0}, index=[0])\n",
    "        cont_rotation = pd.concat([zero_row, cont_rotation]).reset_index(drop = True)\n",
    "        #enact a culmulitive sum function that adds together all displacements that came before each row\n",
    "        cont_rotation['continuous theta'] = cont_rotation.cumsum()\n",
    "        #drop the NAN and or first row of zeros to start at the actual first data point\n",
    "        cont_rotation= cont_rotation.apply (pd.to_numeric, errors='coerce')\n",
    "        \n",
    "        cont_rotation = cont_rotation.dropna()\n",
    "        cont_rotation = cont_rotation.reset_index(drop=True)\n",
    "        cont_rotation.drop(index = cont_rotation.index[0], axis = 0, inplace = True)\n",
    "        cont_rotation = cont_rotation.reset_index(drop=True) # cont_rotation is our (-infinity,infinity) degree rotation dataframe\n",
    "        #Now we have a dataframe called cont_rotation that has 2 columns\n",
    "        # first column is displacement with the correction and second column is the culmulitive sum of the first col\n",
    "        # 'continuous theta' is the cumulitive sum of the displacements\n",
    "        \n",
    "        ## Something to look into ##\n",
    "        #the assumption there is that even though that jump looks like a backwards jump of ~175 degrees, its close enough to 180 degrees that the direction could have been mistaken.\n",
    "        #and if we are unsure if we are mistaken then lets look at surrounding frames to get a hint for which direction it is going\n",
    "        #have to do this after calc theta culmulitive\n",
    "    \n",
    "        ## GRAPHING DATA ASSIGNMENT BLOCK##\n",
    "            \n",
    "        # Here the code determines the units of the graph, only for cartesian graphs   \n",
    "        if unit == \"pixel\":\n",
    "            x_unit = 3\n",
    "            y_unit = 4\n",
    "        if unit == \"nm\":\n",
    "            x_unit = 5\n",
    "            y_unit = 6\n",
    "        \n",
    "        #assign values of x y and z\n",
    "        x = df.iloc[frame_start:frame_end,x_unit] # move this outside this block to apply for all \"none\"\n",
    "        y = df.iloc[frame_start:frame_end,y_unit]\n",
    "        z = df.iloc[frame_start:frame_end,7] #col 7 is the time col \n",
    "       \n",
    "        #Assign theta(0,360), time, and theta(-infinity,infinity)-->(continuous degree rotation)\n",
    "        theta = df_theta.iloc[frame_start:frame_end,2]\n",
    "        t = df_theta.iloc[frame_start:frame_end,3]\n",
    "        \n",
    "        thetac = cont_rotation.iloc[frame_start:frame_end,1]\n",
    "        \n",
    "        #determine number of plots from amount of frames desired in each plot\n",
    "        j = int(math.ceil(len(df)/frames_per_plot))\n",
    "        if plot_type == 'grid':\n",
    "            print(*['number of plots:',j])\n",
    "        \n",
    "        \n",
    "        #####################################RADIUS FILTERING#####################################\n",
    "        #labeling my Radius and Zscore data to make it more workable\n",
    "        my_rad = data[\"Radius (nm)\"]  #Stores Radii into an array\n",
    "        my_zscore= data[\"z-score Rad\"] #Stores Z-scores into an array\n",
    "\n",
    "        #Filter for good data: Upper BOUND \n",
    "        if rad_filter_type_upper == \"zscore\":\n",
    "            up_fil = my_zscore < z_up #Create a boolean filter for sus zscores that are too high\n",
    "        else:\n",
    "            up_fil = my_rad < dist_high # if we are not using zscore, we use distance. Gather all the upper sus distances\n",
    "            \n",
    "        #Filter for good data: Lower BOUND\n",
    "        if rad_filter_type_lower == \"zscore\":\n",
    "            down_fil = z_down < my_zscore #Gather lower sus z scores, if we are talking about zscores.\n",
    "        else:\n",
    "            down_fil = dist_low < my_rad # Otherwise let's gather the lower distances that are sus. \n",
    "            \n",
    "        #Filter for valid readings: \n",
    "        \n",
    "        #Section data for Good data (within bounds)\n",
    "        acceptable_ind = down_fil & up_fil\n",
    "        data_fil = data.iloc[:,[7,5,6,8,10]]   # Put Time, X, Y, Radius, and Angle in a dataframe\n",
    "        data_fil = data_fil[acceptable_ind]  # Keep only acceptable values\n",
    "\n",
    "        #Section the eliminated data for both upper and lower\n",
    "        data_fil_bad = data.iloc[:,[7,5,6,8,10]] # Put Time, X, Y, Radius, and Angle in a dataframe\n",
    "        data_fil_bad = data_fil_bad[~acceptable_ind] # keep only NOT acceptable Values\n",
    "                #### NOTE: Unacceptable values does not include those\n",
    "        \n",
    "        #Section the eliminated data for UPPER and LOWER separately\n",
    "            #lower:\n",
    "        data_fil_down_bad = data.iloc[:,[0,7,5,6,8,10]]\n",
    "        data_fil_down_bad = data_fil_down_bad[~down_fil] #filter for the ones that do not meet the lower cut off\n",
    "\n",
    "            #upper\n",
    "        data_fil_up_bad = data.iloc[:,[0,7,5,6,8,10]]\n",
    "        data_fil_up_bad = data_fil_up_bad[~up_fil]\n",
    "        \n",
    "        #As a reminder , invalid points will be sectioned using \n",
    "        ind_invalid_reading\n",
    "        \n",
    "\n",
    "        #What data am I graphing? the filtered X values and Filtered Y values\n",
    "        x_good = data_fil[\"X displacement (nm)\"]\n",
    "        y_good = data_fil[\"Y displacement (nm)\"]\n",
    "        x_bad = data_fil_bad[\"X displacement (nm)\"]\n",
    "        y_bad = data_fil_bad[\"Y displacement (nm)\"]\n",
    "        \n",
    "        ######################################### ANGLE CALCULATION ###########################################\n",
    "        \n",
    "        #Marginal Angle calculation using the my_diff function\n",
    "        def my_diff(vec):\n",
    "            \n",
    "            vect = vec.diff() # run a differential on all the angles\n",
    "            \n",
    "            vect[0] = 0 # set the first NaN to 0\n",
    "            \n",
    "            \n",
    "            #assuming all increments are less than 180, \n",
    "            #then make all changes bigger than 180, less than 180. \n",
    "            \n",
    "            vect[vect >=(180)] -= 360 # greater than 180 --> negative equivalent\n",
    "\n",
    "            vect[vect <=(-180)] += 360 # less than -180 --> positive equivalent\n",
    "            \n",
    "            return vect\n",
    "        \n",
    "        #_________________________________________[UNFLITERED DATA]__________________________________________________________\n",
    "    \n",
    "        my_ang_diff = my_diff(data[\"Angle\"])\n",
    "        \n",
    "        \n",
    "        data[\"Delta Angle\"] = my_ang_diff #Store corrected differentials into a an array \n",
    "        \n",
    "        #Subtract away the orginal angle \n",
    "        my_ang_cumsum = my_ang_diff.cumsum()\n",
    "\n",
    "        \n",
    "        data[\"Continuous Angle\"] = my_ang_cumsum\n",
    "        \n",
    "        \n",
    "        #_________________________________________[FILTERED DATA]__________________________________________________________\n",
    "        my_ang_diff = my_diff(data[\"Angle\"]) # run the specialized differential function on the Angles and store it\n",
    "        \n",
    "        #DELTA ANGLE\n",
    "        data[\"Delta Angle\"] = my_ang_diff #Store corrected differentials into a an array \n",
    "        \n",
    "        #CONTINUOUS ANGLE: continuous sumation of the differentials  \n",
    "        my_ang_cumsum = my_ang_diff.cumsum() #Run running summation fnction on differential angle\n",
    "\n",
    "        data[\"Continuous Angle\"] = my_ang_cumsum #Store the cummulative angle data in the \"data\" dataframe\n",
    "        \n",
    "        avt = data[[\"index\",\"Time (ms)\",\"Angle\"]].copy(deep=True) #Make an array to hold all the data from Angle vs time (avt) data\n",
    "\n",
    "        avt_good = avt[acceptable_ind] #Filter for the acceptable indices\n",
    "\n",
    "        avt_good = pd.DataFrame(avt_good) # make it its own dataframe\n",
    "\n",
    "        avt_bad = avt[~acceptable_ind] #Filter for the unacceptable indices\n",
    "\n",
    "        avt_bad = pd.DataFrame(avt_bad) # make it its own dataframe\n",
    "\n",
    "        \n",
    "        # How are we dealing with the BAD Angles? \n",
    "        # Let's get rid of their values from \"data\" and replace them as NaN. \n",
    "        avt_bad[\"Del Angle\"] = np.nan #Set all the bad Del Angles to NaN\n",
    "        avt_bad[\"Continuous Angle\"] = np.nan # set all the bad Continuous angles to NaN\n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        #How are we dealing with GOOD Angles?\n",
    "        # Run specialized diff function on the good angles and store into a column in \"the good dataframe\"\n",
    "        avt_good[\"Del Angle\"] = my_diff(avt_good[\"Angle\"]) \n",
    "        #Calculate Del angle and cmli\n",
    "        avt_good[\"Continuous Angle\"] = avt_good[\"Del Angle\"].cumsum()\n",
    "        \n",
    "        ################################## Run Downsampling on filtered Data#####################3\n",
    "        my_fil_arr = avt_good.to_numpy() # convert my data frame into numpy array\n",
    "        data_fil_pre_dsa = my_fil_arr[:,1:5] # section all columns but the index column\n",
    "        num_row = np.size(data_fil_pre_dsa,0) # find the rows of data_fil_pre_dsa\n",
    "        num_col = np.size(data_fil_pre_dsa,1) # find columns of data_fil_pre_dsa\n",
    "        num_row = math.floor(num_row/bin_size) # Re adjust the number of rows with ratio of 1 row per 1 bin_size\n",
    "        data_fil_dsa1 = np.zeros((num_row,num_col)) # Intialize data table to fill\n",
    "        vec = np.arange(0,num_col) # Define variable for for loop\n",
    "        for i in vec:  # for each column, run the average downsampling function and store in matrix\n",
    "            data_fil_dsa1[:,i] = average(data_fil_pre_dsa[:,i],bin_size)\n",
    "        #make np matrix a dataframe \n",
    "        data_fil_dsa = pd.DataFrame(data_fil_dsa1, columns = ['Time (ms)','Angle','Del Angle','Continuous Angle'])\n",
    "            \n",
    "        ################################### [Final Data Table Assembly ] ######################################\n",
    "           \n",
    "        \n",
    "        #Organzize Data Table with Final Filtered Data [Re insert sus points from lower and upper bound filtering]\n",
    "        data_final = pd.concat([avt_good,avt_bad]) #slap all the bad data on the end of the good data\n",
    "        # sort by index so that values go back to where they are supposed to be:\n",
    "        data_final = data_final.sort_values( by = [\"index\"])\n",
    "        \n",
    "        # re insert sus points [re insert sus points from invalid] \n",
    "        #Organzize Data Table with Front End data (data) and back end data (data_back)\n",
    "        data_final_final = pd.concat([data_back,data_final]) #slap all the bad data on the end of the good data\n",
    "        # sort by index so that values go back to where they are supposed to be:\n",
    "        data_final_final = data_final_final.sort_values( by = [\"index\"])\n",
    "\n",
    "        del data_final_final['X position']\n",
    "        del data_final_final['Y position']\n",
    "        \n",
    "        \n",
    "        #Label of the Data with either Normal, Upper bound, Lower Bound, Invalid Reading\n",
    "        \n",
    "            # Initialize the data table to be populated\n",
    "        data_final_final[\"Sus Type\"] = 'None'\n",
    "            # store this into a dummy vector\n",
    "        dummy_vec = data_final_final[\"Sus Type\"].copy()\n",
    "\n",
    "\n",
    "            # Set all indices of AVT_good to normal\n",
    "        ind_Normal = avt_good[\"index\"].copy() #Select all indicies that are NORMAL --> avt_good indicies \n",
    "        dummy_vec[ind_Normal] = 'Normal'\n",
    "\n",
    "\n",
    "            #Set all indicies of data_back to 'Invalid Reading' and put them in the dummy variable \n",
    "        ind_IR = data_back[\"index\"].copy()\n",
    "        dummy_vec[ind_IR] = 'Invalid Reading'\n",
    "\n",
    "            #Find bad lower bounds and index for them and set value to \"below bound\"\n",
    "        ind_bad_down = data_fil_down_bad[\"index\"].copy()\n",
    "        dummy_vec[ind_bad_down] = 'Below Bound'\n",
    "\n",
    "            #fFind bad upper bounds and index for them and set value to \"upper bound\"\n",
    "        ind_bad_up = data_fil_up_bad[\"index\"].copy()\n",
    "        dummy_vec[ind_bad_up] = 'Above Bound'\n",
    "\n",
    "        data_final_final[\"Sus Type\"] = dummy_vec\n",
    "        data_final_final = data_final_final[[\"index\",\"Time (ms)\", \"Angle\",\"Del Angle\",\"Continuous Angle\",\"Sus Type\"]]\n",
    "        \n",
    "        if save_filtered_table == \"yes\":\n",
    "            data_final_final.to_csv('my_final_data_table_v1.csv', index = \"false\")\n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "        #####################################GRAPHING BLOCK##############################\n",
    "            \n",
    "        if plot_type == \"2D\":\n",
    "            \n",
    "            # changes setting\n",
    "            %matplotlib notebook \n",
    "            \n",
    "            \n",
    "            fig = plt.figure(figsize=(6,6), dpi=100)\n",
    "            ax = fig.add_subplot(111) # this comand is here to take advantage of the \"axes\" plotting library\n",
    "\n",
    "\n",
    "            \n",
    "            #color bar color scheme assignment, graph type, colorbar size and alignment\n",
    "            colors = cm.viridis(np.linspace(0, 1, len(z)))\n",
    "            p=ax.scatter(x, y, c=colors, alpha = 0.7)\n",
    "            cbar = plt.colorbar(p, label= z_axis_label ,shrink= .82) \n",
    "\n",
    "            #setting the ticks on the colorbar to span the length of the time column with 6 increments\n",
    "            cbar.set_ticks([0, 0.2, 0.4, 0.6, 0.8, 1]) \n",
    "\n",
    "            tix = np.linspace(0,len(z),6, dtype = int) # forces colorbar to show time in integers\n",
    "            tix_c = tix*time_step\n",
    "            cbar.set_ticklabels(tix_c) \n",
    "            plt.axis('square')\n",
    "            plt.xticks(rotation=45)\n",
    "            \n",
    "            #display center\n",
    "            if display_center == \"yes\":\n",
    "                center1 = [0,0] # in a centered graph, the center is actually(0,0)\n",
    "                ax.scatter(0, 0, color = 'Magenta', marker = \"X\", s=150) # plots center point as magenta X\n",
    "                plt.text(x = center1[0] +0.02, y = center1[1] +0.02, s = 'CENTER')\n",
    "                \n",
    "            #set graph limit conditions depending on unit specified\n",
    "            if unit == \"pixel\":\n",
    "                ax.set_xlim(pixel_min, pixel_max) \n",
    "                ax.set_ylim(pixel_min, pixel_max)\n",
    "                ax.yaxis.set_major_locator(ticker.LinearLocator(axis_increment_pixel))\n",
    "                ax.xaxis.set_major_locator(ticker.LinearLocator(axis_increment_pixel))\n",
    "            if unit == \"nm\":\n",
    "                ax.set_xlim(nm_min, nm_max) \n",
    "                ax.set_ylim(nm_min, nm_max)\n",
    "                ax.yaxis.set_major_locator(ticker.LinearLocator(axis_increment_nm))\n",
    "                ax.xaxis.set_major_locator(ticker.LinearLocator(axis_increment_nm))\n",
    "            \n",
    "            ## Jerry Adds a hover cursor\n",
    "            mplcursors.cursor(hover=True)\n",
    "            mplcursors.cursor(highlight=True)\n",
    "            \n",
    "            #axis labels and font configurations\n",
    "            ax.set_xlabel(x_axis_label, fontweight = 'bold', fontsize = 14)\n",
    "            ax.set_ylabel(y_axis_label, fontweight = 'bold', fontsize = 14)\n",
    "\n",
    "            # plot title and font configurations\n",
    "            plt.title(title , fontweight = 'bold', fontsize = 16)\n",
    "            \n",
    "            if save_plot == \"yes\":\n",
    "                plt.savefig(title+\"_2D.png\") #put title input and date time\n",
    "            \n",
    "\n",
    "        #grid plot\n",
    "            \n",
    "        if plot_type == \"grid\":\n",
    "            i = 0\n",
    "            dfs = np.array_split(df,j) # splits large dataframe into \"j\" equal dataframes\n",
    "            #print (dfs[i]) #<--- command to print each dataframe # dataframe 0 is the first dataframe\n",
    "            \n",
    "            #this portion specifies subplot dimentions (N plots in 3 columns and amount of appropriate rows)\n",
    "            cols = columns\n",
    "            rows = int(math.ceil(j / cols)) #determining rows based on the number of graphs and columns\n",
    "\n",
    "            gs = gridspec.GridSpec(rows, cols, wspace = .25, hspace = .25)# disallows overlap\n",
    "            fig = plt.figure(figsize = (fig_size_x,fig_size_y))\n",
    "            \n",
    "            while i < j:\n",
    "                    \n",
    "                x = dfs[i].iloc[:,x_unit] \n",
    "                y = dfs[i].iloc[:,y_unit]\n",
    "                z = dfs[i].iloc[:,7]\n",
    "                ax = fig.add_subplot(gs[i])\n",
    "                do_plot(ax)\n",
    "                i+= 1\n",
    "                   \n",
    "            if save_plot == \"yes\":\n",
    "                \n",
    "                framestr = '{}'.format(frames_per_plot)\n",
    "                plt.savefig(title+'_'+framestr+'_frames_per_plot'+'_gridplot.png', dpi=300)\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "        # Angular plot\n",
    "        \n",
    "        if plot_type == \"angular\":\n",
    "            import plotly.express as px\n",
    "\n",
    "            fig = px.scatter(x = t, y = theta, title = title, width=1000, height=500)\n",
    "           \n",
    "            fig.update_traces(hovertemplate='Time (ms): %{x} <br>Theta: %{y}')\n",
    "            \n",
    "        \n",
    "            fig.update_layout(\n",
    "            xaxis_title=\"Time (ms)\",\n",
    "            yaxis_title=\"Theta (degrees)\")\n",
    "            \n",
    "\n",
    "            fig.update_layout(\n",
    "            yaxis = dict(\n",
    "            tickmode = 'linear',\n",
    "            tick0 = 360,\n",
    "            dtick = 45))\n",
    "            fig.show()\n",
    "            \n",
    "            if save_plot == \"yes\":\n",
    "                fig.write_image(title+\"_angular.png\") \n",
    "\n",
    "           \n",
    "            \n",
    "        if plot_type == \"angular_continuous\":\n",
    "            \n",
    "            import plotly.express as px\n",
    "\n",
    "            \n",
    "            fig = px.line(x=t, y=thetac, title = 'Continuous Angular Rotation')\n",
    "            fig.update_traces(hovertemplate='Time (ms): %{x} <br>Theta: %{y}')\n",
    "            \n",
    "            fig.update_layout(\n",
    "            xaxis_title=\"Time (ms)\",\n",
    "            yaxis_title=\"Theta (degrees)\")\n",
    "            \n",
    "            fig.update_layout(\n",
    "            xaxis = dict(\n",
    "            tickmode = 'linear',\n",
    "            tick0 = 0,\n",
    "            dtick = 1000))\n",
    "            \n",
    "            fig.update_layout(\n",
    "            yaxis = dict(\n",
    "            tickmode = 'linear',\n",
    "            tick0 = -360,\n",
    "            dtick = 180))\n",
    "            \n",
    "            \n",
    "                        \n",
    "            fig.show()\n",
    "            if save_plot == \"yes\":\n",
    "                fig.write_image(title+\"_angular_continuous.png\") \n",
    "\n",
    "            \n",
    "        #This block plots a static 3D graph if prompt is met\n",
    "        if plot_type == \"3D\":\n",
    "\n",
    "\n",
    "            #This block splices the segments between data points and assigns each segment to a color\n",
    "            points = np.array([x,y,z]).transpose().reshape(-1,1,3)\n",
    "            segs = np.concatenate([points[:-1],points[1:]],axis=1)\n",
    "            lc = Line3DCollection(segs, cmap = plt.get_cmap('cool'))\n",
    "            lc.set_array(z)\n",
    "\n",
    "            #This block plots the figure at a specified size, in 3D configuration, sets axis range, gathers the \n",
    "            #colored segments from above, and assigns labels\n",
    "            fig = plt.figure(figsize=(8,8))\n",
    "            ax = fig.gca(projection = '3d')\n",
    "            ax.set_zlim(min(z), max(z))\n",
    "            if unit == \"pixel\":\n",
    "                ax.set_xlim(-1,1)\n",
    "                ax.set_ylim(-1,1)\n",
    "            if unit == \"nm\":\n",
    "                ax.set_xlim(-150,150)\n",
    "                ax.set_ylim(-150,150)\n",
    "            ax.add_collection3d(lc, zs=z, zdir='z')\n",
    "            plt.title(title , fontweight = 'bold', fontsize= 16)\n",
    "            ax.set_xlabel(x_axis_label, fontweight = 'bold', fontsize = 14)\n",
    "            ax.set_ylabel(y_axis_label , fontweight = 'bold', fontsize = 14)\n",
    "            ax.set_zlabel(z_axis_label, fontweight= 'bold' , fontsize =14)\n",
    "            \n",
    "            if save_plot == 'yes':\n",
    "                plt.savefig(title+'_3D.png',dpi=300)\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "        if plot_type == \"interactive\":\n",
    "\n",
    "            #configure plot settings (currently called trace 1, may add more traces in the future)\n",
    "            trace1=go.Scatter3d(x=x,\n",
    "                                y=y,\n",
    "                                z=z,\n",
    "                                mode = \"lines\",\n",
    "                                name = 'Original',\n",
    "                                marker=dict(\n",
    "                                    size=4,\n",
    "                                    color='#e9ebf0',\n",
    "                                    opacity=0.7,\n",
    "                                    showscale=False,\n",
    "                                    colorbar=dict(\n",
    "                                        title='Time (ms)')),\n",
    "                                line=dict(\n",
    "                                    color='#e9ebf0',\n",
    "                                    width=2))\n",
    "            #assign traces\n",
    "            fig = go.Figure(data=[trace1])\n",
    "\n",
    "            #assign title\n",
    "            fig.update_layout(title= title)\n",
    "            #assign axis labels\n",
    "            fig.update_layout(scene = dict(\n",
    "                        xaxis_title= x_axis_label,\n",
    "                        yaxis_title= y_axis_label,\n",
    "                        zaxis_title= z_axis_label)) \n",
    "\n",
    "            #Here we can tweak the background color, grid color, and color of the origin for all axes/plane\n",
    "            fig.update_layout(scene = dict(\n",
    "                        xaxis = dict(\n",
    "                             backgroundcolor=\"black\",\n",
    "                             gridcolor=\"gray\",\n",
    "                             showbackground=True,\n",
    "                             zerolinecolor=\"white\",),\n",
    "                        yaxis = dict(\n",
    "                            backgroundcolor=\"black\",\n",
    "                            gridcolor=\"gray\",\n",
    "                            showbackground=True,\n",
    "                            zerolinecolor=\"white\"),\n",
    "                        zaxis = dict(\n",
    "                            backgroundcolor=\"black\",\n",
    "                            gridcolor=\"gray\",\n",
    "                            showbackground=True,\n",
    "                            zerolinecolor=\"white\"),),\n",
    "                      )\n",
    "\n",
    "            #size and aspect ratio of the graph and the default camera zoom and angle \n",
    "            fig.update_layout(\n",
    "            width=800,\n",
    "            height=700,\n",
    "            autosize=False,\n",
    "            scene=dict(\n",
    "            camera=dict(\n",
    "                up=dict(\n",
    "                    x=0,\n",
    "                    y=0,\n",
    "                    z=1\n",
    "                ),\n",
    "                eye=dict(\n",
    "                    x=1,\n",
    "                    y=2,\n",
    "                    z=2,\n",
    "                )\n",
    "            ),\n",
    "            aspectratio = dict( x=1, y=1, z=4 ),\n",
    "            aspectmode = 'manual'\n",
    "            ),\n",
    "            )\n",
    "            \n",
    "            \n",
    "\n",
    "            fig.show()\n",
    "            \n",
    "            ## Easter Egg slider plot, cudos to the person who can get this to work properly ##\n",
    "        if plot_type == 'slider':\n",
    "            \n",
    "            %matplotlib notebook\n",
    "            #reassigning to a dataframe, setting up axis with empty list, aspect ratio\n",
    "            coord = pd.DataFrame(x)\n",
    "            coord.columns = ['x']\n",
    "            coord['y'] = y\n",
    "            fig = plt.figure()\n",
    "            ax = fig.add_subplot(111)\n",
    "            scat = ax.scatter(coord.x.values,coord.y.values) \n",
    "            plt.axis('square')\n",
    "\n",
    "            \n",
    "            # chosing units\n",
    "            if unit == \"pixel\":\n",
    "                    ax.set_xlim(pixel_min, pixel_max) \n",
    "                    ax.set_ylim(pixel_min, pixel_max)\n",
    "                    ax.yaxis.set_major_locator(ticker.LinearLocator(axis_increment_pixel))# change to 5 for increments of .5\n",
    "                    ax.xaxis.set_major_locator(ticker.LinearLocator(axis_increment_pixel))\n",
    "                    ax.grid()\n",
    "            if unit == \"nm\":\n",
    "                    ax.set_xlim(nm_min, nm_max) \n",
    "                    ax.set_ylim(nm_min, nm_max)\n",
    "                    ax.yaxis.set_major_locator(ticker.LinearLocator(axis_increment_nm))\n",
    "                    ax.xaxis.set_major_locator(ticker.LinearLocator(axis_increment_nm))\n",
    "                    ax.grid()\n",
    "            ax.set_xlabel(x_axis_label, fontweight = 'bold', fontsize = 12)\n",
    "            ax.set_ylabel(y_axis_label, fontweight = 'bold', fontsize = 12)\n",
    "\n",
    "            # plot title and font configurations\n",
    "            plt.title(title , fontweight = 'bold', fontsize = 16)\n",
    "            \n",
    "\n",
    "            axslider = plt.axes([0.125, 0.01, 0.775, 0.05])\n",
    "            slider = Slider(axslider,'test', valmin=tail_length, valmax=1400, valinit=1, valstep=1, color = 'green')\n",
    "            scat.set_offsets(np.c_[0,0])\n",
    "            \n",
    "            def update(val):\n",
    "                \n",
    "                \n",
    "                i = int(slider.val)\n",
    "                scat.set_offsets(np.c_[coord.x.values[i-tail_length:i],coord.y.values[i-tail_length:i]])\n",
    "                cmap = plt.cm.Greens\n",
    "                norm = plt.Normalize(vmin=0, vmax=10)\n",
    "                z = np.array(range(tail_length))\n",
    "                \n",
    "                c = cmap(norm(z))\n",
    "                print(\"C1 is running\") #EDIT\n",
    "                scat.set_color(c)\n",
    "                fig.canvas.draw_idle()\n",
    "                print('test')\n",
    "                return fig, scat,\n",
    "            \n",
    "            slider.on_changed(update)\n",
    "\n",
    "\n",
    "            plt.show()\n",
    "        if plot_type == 'slider':\n",
    "            plt.show()\n",
    "            print(\"C\")\n",
    "            return scat, slide, fig\n",
    "            \n",
    "        \n",
    "        if plot_type == \"animated\" or plot_type == 'HTML':\n",
    "            # allows for animation to animate\n",
    "            %matplotlib notebook\n",
    "            #reassigning to a dataframe, setting up axis with empty list, aspect ratio\n",
    "            coord = pd.DataFrame(x)\n",
    "            coord.columns = ['x']\n",
    "            coord['y'] = y\n",
    "            fig = plt.figure()\n",
    "            ax = fig.add_subplot(111)\n",
    "            sc = ax.scatter([], [])\n",
    "            plt.axis('square')\n",
    "            \n",
    "            # chosing units\n",
    "            if unit == \"pixel\":\n",
    "                    ax.set_xlim(pixel_min, pixel_max) \n",
    "                    ax.set_ylim(pixel_min, pixel_max)\n",
    "                    ax.yaxis.set_major_locator(ticker.LinearLocator(axis_increment_pixel))# change to 5 for increments of .5\n",
    "                    ax.xaxis.set_major_locator(ticker.LinearLocator(axis_increment_pixel))\n",
    "                    ax.grid()\n",
    "            if unit == \"nm\":\n",
    "                    ax.set_xlim(nm_min, nm_max) \n",
    "                    ax.set_ylim(nm_min, nm_max)\n",
    "                    ax.yaxis.set_major_locator(ticker.LinearLocator(axis_increment_nm))\n",
    "                    ax.xaxis.set_major_locator(ticker.LinearLocator(axis_increment_nm))\n",
    "                    ax.grid()\n",
    "            ax.set_xlabel(x_axis_label, fontweight = 'bold', fontsize = 12)\n",
    "            ax.set_ylabel(y_axis_label, fontweight = 'bold', fontsize = 12)\n",
    "\n",
    "            # plot title and font configurations\n",
    "            plt.title(title , fontweight = 'bold', fontsize = 16)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # animation function feeds a window of dataframe values into the graphing function at a time,\n",
    "            # iterates over user specified range in dataframe with user specified tail length\n",
    "            # color of animation is also specified here\n",
    "            def animate(count):\n",
    "                sc.set_offsets(np.c_[coord.x.values[count-tail_length:count],coord.y.values[count-tail_length:count]])\n",
    "                cmap = plt.cm.Greens\n",
    "                norm = plt.Normalize(vmin=0, vmax=tail_length)\n",
    "                z = np.array(range(tail_length))\n",
    "                c = cmap(norm(z))\n",
    "                sc.set_color(c)\n",
    "                #button_ax = plt.axes([.78, .87, .1, .07]) # creates an outline for a potential button\n",
    "               \n",
    "                \n",
    "                return \n",
    "\n",
    "            ani = FuncAnimation(fig, animate, interval= frame_speed, frames = len(coord)) #frames=len(df)\n",
    "            #ani.toggle(ax=button_ax)# potential button toggle for a potential button ;)\n",
    "            if save_plot == 'yes':\n",
    "                \n",
    "                ani.save(title+'_animation_gif.gif', writer='pillow', fps=10, dpi=100)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            # With out the added if statement below, the animated plot will not animate \n",
    "            #(due to being a nested function)\n",
    "        if plot_type == 'animated': \n",
    "\n",
    "                \n",
    "\n",
    "            return ani\n",
    "        # \n",
    "        if plot_type == 'HTML':\n",
    "            plt.close('all')\n",
    "            if save_plot == 'yes':\n",
    "                with open(title+\"_animation_html.html\", \"w\") as f:\n",
    "                    print(ani.to_jshtml(), file=f)\n",
    "            return HTML(ani.to_jshtml())\n",
    "        \n",
    "        \n",
    "        ###################JERRY's GRAPHING SECTION ##########################\n",
    "        \n",
    "        #Radius Filtering: Determines which data points are bad visually from the 2D plot \n",
    "        if plot_type == \"radius_filter\":\n",
    "            \n",
    "            # changes setting\n",
    "            %matplotlib notebook \n",
    "            \n",
    "            fig = plt.figure(figsize=(6,6), dpi=100)\n",
    "            ax = fig.add_subplot(111) # this comand is here to take advantage of the \"axes\" plotting library\n",
    "            \n",
    "            #color bar color scheme assignment, graph type, colorbar size and alignment\n",
    "            colors = cm.viridis(np.linspace(0, 1, len(x_good)))\n",
    "            p=ax.scatter(x_good, y_good, c=colors, alpha = 0.7)\n",
    "            cbar = plt.colorbar(p, label= z_axis_label ,shrink= .82)\n",
    "            \n",
    "            #graph bad data and make a \n",
    "            ax.scatter( x_bad, y_bad, c='r', marker=\"o\", label='BAD')\n",
    "            ax.legend(loc='lower right', bbox_to_anchor=(0.5, 0),fancybox=True, shadow=True)\n",
    "            \n",
    "            # add a red dot to indicate center of trajectory\n",
    "            if display_center == \"yes\":\n",
    "                center1 = [0,0] # in a centered graph, the center is actually(0,0)\n",
    "                ax.scatter(0, 0, color = 'Magenta', marker = \"X\", s=150) # plots center point as magenta X\n",
    "                #plt.text(x = center1[0] +0.02, y = center1[1] +0.02, s = 'CENTER')\n",
    "\n",
    "            #setting the ticks on the colorbar to span the length of the time column with 6 increments\n",
    "            cbar.set_ticks([0, 0.2, 0.4, 0.6, 0.8, 1]) \n",
    "\n",
    "            tix = np.linspace(0,len(x_good),6, dtype = int) # forces colorbar to show time in integers\n",
    "            tix_c = tix*time_step\n",
    "            cbar.set_ticklabels(tix_c) \n",
    "            plt.axis('square')\n",
    "            plt.xticks(rotation=45)\n",
    "\n",
    "            #set graph limit conditions depending on unit specified\n",
    "            if unit == \"pixel\":\n",
    "                ax.set_xlim(pixel_min, pixel_max) \n",
    "                ax.set_ylim(pixel_min, pixel_max)\n",
    "                ax.yaxis.set_major_locator(ticker.LinearLocator(axis_increment_pixel))\n",
    "                ax.xaxis.set_major_locator(ticker.LinearLocator(axis_increment_pixel))\n",
    "            if unit == \"nm\":\n",
    "                ax.set_xlim(nm_min, nm_max) \n",
    "                ax.set_ylim(nm_min, nm_max)\n",
    "                ax.yaxis.set_major_locator(ticker.LinearLocator(axis_increment_nm))\n",
    "                ax.xaxis.set_major_locator(ticker.LinearLocator(axis_increment_nm))\n",
    "            \n",
    "            ## Jerry Adds a hover cursor\n",
    "            mplcursors.cursor(hover=True)\n",
    "            mplcursors.cursor(highlight=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            #axis labels and font configurations\n",
    "            ax.set_xlabel(x_axis_label, fontweight = 'bold', fontsize = 14)\n",
    "            ax.set_ylabel(y_axis_label, fontweight = 'bold', fontsize = 14)\n",
    "\n",
    "            # plot title and font configurations\n",
    "            plt.title(title , fontweight = 'bold', fontsize = 16)\n",
    "            \n",
    "            if save_plot == \"yes\":\n",
    "                plt.savefig(title+\"_2D.png\") #put title input and date time\n",
    "        \n",
    "        \n",
    "        #Jerry_replots the angle continuous datpoint out the sus angles in Claire's graph\n",
    "        if plot_type == \"find_sus_angle_CR\":\n",
    "            \n",
    "            #setup\n",
    "            %matplotlib notebook\n",
    "            \n",
    "            #data organization\n",
    "            times = t\n",
    "            conti_angle = thetac\n",
    "            \n",
    "            #setup fig and ax\n",
    "            fig,ax = plt.subplots()\n",
    "            \n",
    "            if graph_style == 'scatter':\n",
    "                ax.scatter(times,conti_angle, c = 'b', s = 5)\n",
    "            else:\n",
    "                line, = plt.plot(times,conti_angle,'b')\n",
    "            \n",
    "            \n",
    "#           setting up for making vertical lines or indications of bad points (high and low points)\n",
    "            ang_min = min(conti_angle)\n",
    "            ang_max = max(conti_angle)\n",
    "        \n",
    "            #find and graph lower bad values\n",
    "            bad_times_down = data_fil_down_bad[\"Time (ms)\"] \n",
    "            ax.vlines([bad_times_down], ang_min, ang_max, linestyles = 'dashed', colors = 'maroon')\n",
    "            \n",
    "            # find and graph upper bad values\n",
    "            bad_times_up = data_fil_up_bad[\"Time (ms)\"] \n",
    "            ax.vlines([bad_times_up], ang_min, ang_max, linestyles = 'dashed', colors = 'tomato')\n",
    "            \n",
    "            # find and graph the invalid bad values\n",
    "            invalid_times = data_back[\"Time (ms)\"]\n",
    "            ax.vlines([invalid_times], ang_min, ang_max, linestyles = 'dashed', colors = 'darkcyan')\n",
    "            \n",
    "            #Legend\n",
    "            ax.legend(['Angle data', 'Lower Sus','Upper Sus','Invalid Readings'], loc = 'lower right')\n",
    "            \n",
    "            \n",
    "            #formatting\n",
    "            plt.rcParams['figure.figsize'] = [13,6]\n",
    "            \n",
    "            plt.xlabel('Time (ms)')\n",
    "            plt.ylabel('Angle Accumulation (degrees)')\n",
    "            plt.title('Accumulation of Angle (theta) as a function of Time (ms)')\n",
    "            \n",
    "        \n",
    "            plt.xlim(0,max(times)+1000)\n",
    "            plt.ylim(-180,max(conti_angle)+180)\n",
    "            ax.set_xticks(np.arange(0, max(times)+1000, 1000))\n",
    "            ax.set_yticks(np.arange(-360, max(conti_angle)+180, 180))\n",
    "            plt.xticks(rotation = -45)\n",
    "            plt.grid()\n",
    "            \n",
    "            #hovering attempt 2\n",
    "            #added by Jerry for Matplotlib compatible hovering\n",
    "            mplcursors.cursor(hover=True)\n",
    "            \n",
    "        #Jerry_replots the angle continuous data \n",
    "        #This graph is a graph of the JW angular continuous with problematic points still in there\n",
    "        #The lines indicate where problematic data points exist\n",
    "        \n",
    "        if plot_type == \"find_sus_angle_JW\":\n",
    "            \n",
    "            #setup\n",
    "            %matplotlib notebook\n",
    "            \n",
    "            #data organization\n",
    "            times = data[\"Time (ms)\"]\n",
    "            conti_angle = data[\"Continuous Angle\"]\n",
    "            \n",
    "            # setup fig and ax \n",
    "            fig,ax = plt.subplots()\n",
    "            \n",
    "            #choose scatter plot or line plot \n",
    "            if graph_style == 'scatter':\n",
    "                ax.scatter(times,conti_angle, c = 'b', s = 5)\n",
    "            else:\n",
    "                line, = plt.plot(times,conti_angle,'b')\n",
    "        \n",
    "            #setting up for making vertical lines or indications of bad points (high and low points)\n",
    "            ang_min = min(conti_angle)\n",
    "            ang_max = max(conti_angle)\n",
    "        \n",
    "            #find and graph lower bad values\n",
    "            bad_times_down = data_fil_down_bad[\"Time (ms)\"] \n",
    "            ax.vlines([bad_times_down], ang_min, ang_max, linestyles = 'dashed', colors = 'maroon')\n",
    "            \n",
    "            # find and graph upper bad values\n",
    "            bad_times_up = data_fil_up_bad[\"Time (ms)\"] \n",
    "            ax.vlines([bad_times_up], ang_min, ang_max, linestyles = 'dashed', colors = 'tomato')\n",
    "            \n",
    "            # find and graph the invalid bad values\n",
    "            invalid_times = data_back[\"Time (ms)\"]\n",
    "            ax.vlines([invalid_times], ang_min, ang_max, linestyles = 'dashed', colors = 'darkcyan')\n",
    "            \n",
    "            #Legend\n",
    "            ax.legend(['Angle data', 'Lower Sus','Upper Sus','Invalid Readings'], loc = 'lower right')\n",
    "        \n",
    "            #formatting\n",
    "            plt.rcParams['figure.figsize'] = [13,6]\n",
    "            \n",
    "            plt.xlabel('Time (ms)')\n",
    "            plt.ylabel('Angle Accumulation (degrees)')\n",
    "            plt.title('Accumulation of Angle (theta) as a function of Time (ms)')\n",
    "            \n",
    "        \n",
    "            plt.xlim(0,max(times)+1000)\n",
    "#             plt.ylim(-180,max(conti_angle)+180)\n",
    "            ax.set_xticks(np.arange(0, max(times)+1000, 1000))\n",
    "            ax.set_yticks(np.arange(-360, max(conti_angle)+180, 180))\n",
    "            plt.xticks(rotation = -45)\n",
    "            plt.grid()\n",
    "            \n",
    "            #hovering attempt 2\n",
    "            #added by Jerry for Matplotlib compatible hovering\n",
    "            mplcursors.cursor(hover=True)\n",
    "            \n",
    "            \n",
    "        #Graph the newly calcuated Angular Continuous data, now filtered for good points only \n",
    "        if plot_type == \"angular_continuous_filtered\":\n",
    "            #setup\n",
    "            %matplotlib notebook\n",
    "\n",
    "            #data organization\n",
    "            times = avt_good[\"Time (ms)\"]\n",
    "            conti_angle = avt_good[\"Continuous Angle\"]\n",
    "            \n",
    "            #Graph a Scatter Plot otherwize the hover tool hovers to made up points\n",
    "            fig,ax = plt.subplots()\n",
    "            \n",
    "            if graph_style == 'scatter':\n",
    "                ax.scatter(times,conti_angle, c = 'b', s = 5)\n",
    "            else:\n",
    "                line, = plt.plot(times,conti_angle,'b')\n",
    "                \n",
    "\n",
    "            #setting up for making vertical lines or indications of bad points (high and low points)\n",
    "            ang_min = min(conti_angle)\n",
    "            ang_max = max(conti_angle)\n",
    "\n",
    "            #find and graph lower bad values\n",
    "            bad_times_down = data_fil_down_bad[\"Time (ms)\"] \n",
    "            ax.vlines([bad_times_down], ang_min, ang_max, linestyles = 'dashed', colors = 'red')\n",
    "\n",
    "            # find and graph upper bad values\n",
    "            bad_times_up = data_fil_up_bad[\"Time (ms)\"] \n",
    "            ax.vlines([bad_times_up], ang_min, ang_max, linestyles = 'dashed', colors = 'black')\n",
    "\n",
    "            # find and graph the invalid bad values\n",
    "            invalid_times = data_back[\"Time (ms)\"]\n",
    "            ax.vlines([invalid_times], ang_min, ang_max, linestyles = 'dashed', colors = 'darkcyan')\n",
    "            \n",
    "            #Legend\n",
    "            ax.legend(['Angle data', 'Lower Sus','Upper Sus','Invalid Readings'], loc = 'lower right')\n",
    "            \n",
    "            #formatting\n",
    "            plt.rcParams['figure.figsize'] = [13,6]\n",
    "\n",
    "            plt.xlabel('Time (ms)')\n",
    "            plt.ylabel('Angle Accumulation (degrees)')\n",
    "            plt.title('Accumulation of Angle (deg) as a function of Time (ms)')\n",
    "\n",
    "\n",
    "            plt.xlim(0,max(times)+1000)\n",
    "            plt.ylim(ang_min-180,ang_max+180)\n",
    "            ax.set_xticks(np.arange(0, max(times)+1000, 1000))\n",
    "            ax.set_yticks(np.arange(ang_min-180, ang_max+180, 180))\n",
    "            plt.xticks(rotation = -45)\n",
    "            plt.grid()\n",
    "\n",
    "            #hovering attempt 2\n",
    "            #added by Jerry for Matplotlib compatible hovering\n",
    "            mplcursors.cursor(hover=True)         \n",
    "        \n",
    "        #Graph specific for basal data analysis \n",
    "        if plot_type == \"basal1\":\n",
    "            \n",
    "            #setup\n",
    "            %matplotlib notebook\n",
    "\n",
    "            #data organization\n",
    "            times = avt_good[\"Time (ms)\"]\n",
    "            conti_angle = avt_good[\"Continuous Angle\"]\n",
    "            \n",
    "            \n",
    "            #Cut off value for this graph\n",
    "            frame_end;\n",
    "            \n",
    "            #Select for only data within usage range before light invalidity \n",
    "            times = times.loc[0:frame_end]\n",
    "            conti_angle = conti_angle.loc[0:frame_end]\n",
    "            \n",
    "            \n",
    "            #Graph a Scatter Plot otherwize the hover tool hovers to made up points\n",
    "            fig,ax = plt.subplots()\n",
    "            \n",
    "            if graph_style == 'scatter':\n",
    "                ax.scatter(times,conti_angle, c = 'b', s = 5)\n",
    "            else:\n",
    "                line, = plt.plot(times,conti_angle,'b')\n",
    "                \n",
    "\n",
    "            #setting up for making vertical lines or indications of bad points (high and low points)\n",
    "            ang_min = min(conti_angle)\n",
    "            ang_max = max(conti_angle)\n",
    "\n",
    "            #find and graph lower bad values\n",
    "            bad_times_down = data_fil_down_bad[\"Time (ms)\"] \n",
    "            ax.vlines([bad_times_down], ang_min, ang_max, linestyles = 'dashed', colors = 'red')\n",
    "\n",
    "            # find and graph upper bad values\n",
    "            bad_times_up = data_fil_up_bad[\"Time (ms)\"] \n",
    "            ax.vlines([bad_times_up], ang_min, ang_max, linestyles = 'dashed', colors = 'black')\n",
    "\n",
    "            # find and graph the invalid bad values\n",
    "            invalid_times = data_back[\"Time (ms)\"]\n",
    "            ax.vlines([invalid_times], ang_min, ang_max, linestyles = 'dashed', colors = 'darkcyan')\n",
    "            \n",
    "            #Legend\n",
    "            ax.legend(['Angle data', 'Lower Sus','Upper Sus','Invalid Readings'], loc = 'lower right')\n",
    "            \n",
    "            #formatting\n",
    "            plt.rcParams['figure.figsize'] = [13,6]\n",
    "\n",
    "            plt.xlabel('Time (ms)')\n",
    "            plt.ylabel('Angle Accumulation (degrees)')\n",
    "            plt.title('Accumulation of Angle (deg) as a function of Time (ms)')\n",
    "\n",
    "\n",
    "            plt.xlim(0,max(times))\n",
    "            plt.ylim(ang_min-180,ang_max+180)\n",
    "            ax.set_xticks(np.arange(0, max(times), 1000))\n",
    "            ax.set_yticks(np.arange(ang_min-180, ang_max+180, 180))\n",
    "            plt.xticks(rotation = -45)\n",
    "            plt.grid()\n",
    "\n",
    "            #hovering attempt 2\n",
    "            #added by Jerry for Matplotlib compatible hovering\n",
    "            mplcursors.cursor(hover=True)\n",
    "            \n",
    "        #graphs downsampled version of basal 1\n",
    "        if plot_type == \"basal2\":\n",
    "            \n",
    "            #setup\n",
    "            %matplotlib notebook\n",
    "\n",
    "            #data organization\n",
    "            times = data_fil_dsa[\"Time (ms)\"]\n",
    "            conti_angle = data_fil_dsa[\"Continuous Angle\"]\n",
    "            \n",
    "            #Cut off value for this graph\n",
    "            frame_end;\n",
    "            times_end = frame_end * time_step\n",
    "            \n",
    "            #Select for only data within usage range before light invalidity \n",
    "            \n",
    "            times = times.loc[0:times_end]\n",
    "            conti_angle = conti_angle.loc[0:times_end]\n",
    "            \n",
    "            #Graph a Scatter Plot otherwize the hover tool hovers to made up points\n",
    "            fig,ax = plt.subplots()\n",
    "            \n",
    "            if graph_style == 'scatter':\n",
    "                ax.scatter(times,conti_angle, c = 'b', s = 5)\n",
    "            else:\n",
    "                line, = plt.plot(times,conti_angle,'b')\n",
    "                \n",
    "\n",
    "            #setting up for making vertical lines or indications of bad points (high and low points)\n",
    "            ang_min = min(conti_angle)\n",
    "            ang_max = max(conti_angle)\n",
    "\n",
    "            #find and graph lower bad values\n",
    "            bad_times_down = data_fil_down_bad[\"Time (ms)\"] \n",
    "            ax.vlines([bad_times_down], ang_min, ang_max, linestyles = 'dashed', colors = 'red')\n",
    "\n",
    "            # find and graph upper bad values\n",
    "            bad_times_up = data_fil_up_bad[\"Time (ms)\"] \n",
    "            ax.vlines([bad_times_up], ang_min, ang_max, linestyles = 'dashed', colors = 'black')\n",
    "\n",
    "            # find and graph the invalid bad values\n",
    "            invalid_times = data_back[\"Time (ms)\"]\n",
    "            ax.vlines([invalid_times], ang_min, ang_max, linestyles = 'dashed', colors = 'darkcyan')\n",
    "            \n",
    "            #Legend\n",
    "            ax.legend(['Angle data', 'Lower Sus','Upper Sus','Invalid Readings'], loc = 'lower right')\n",
    "            \n",
    "            #formatting\n",
    "            plt.rcParams['figure.figsize'] = [13,6]\n",
    "\n",
    "            plt.xlabel('Time (ms)')\n",
    "            plt.ylabel('Angle Accumulation (degrees)')\n",
    "            plt.title('Accumulation of Angle (deg) as a function of Time (ms)')\n",
    "\n",
    "\n",
    "            plt.xlim(0,max(times))\n",
    "            plt.ylim(ang_min-180,ang_max+180)\n",
    "            ax.set_xticks(np.arange(0, max(times), 1000))\n",
    "            ax.set_yticks(np.arange(ang_min-180, ang_max+180, 180))\n",
    "            plt.xticks(rotation = -45)\n",
    "            plt.grid()\n",
    "\n",
    "            #hovering attempt 2\n",
    "            #added by Jerry for Matplotlib compatible hovering\n",
    "            mplcursors.cursor(hover=True)  \n",
    "            \n",
    "        #Combination of Basal 1 and Basal 2\n",
    "        if plot_type == \"basal3\":\n",
    "            \n",
    "            #setup\n",
    "            %matplotlib notebook\n",
    "\n",
    "            ##########################data organization######################3\n",
    "            \n",
    "            \n",
    "            #Block 1\n",
    "            \n",
    "            times1 = avt_good[\"Time (ms)\"]\n",
    "            conti_angle1 = avt_good[\"Continuous Angle\"]\n",
    "            \n",
    "            \n",
    "            #Cut off value for this graph\n",
    "            frame_end;\n",
    "            \n",
    "            #Select for only data within usage range before light invalidity \n",
    "            times1 = times1.loc[0:frame_end]\n",
    "            conti_angle1 = conti_angle1.loc[0:frame_end]\n",
    "            \n",
    "            print(\"Graphing block 1 has completed\")\n",
    "            \n",
    "            \n",
    "            #Block 2\n",
    "            times2 = data_fil_dsa[\"Time (ms)\"]\n",
    "            conti_angle2 = data_fil_dsa[\"Continuous Angle\"]\n",
    "            \n",
    "            #Cut off value for this graph\n",
    "            times_end = frame_end * time_step\n",
    "            \n",
    "            #Select for only data within usage range before light invalidity \n",
    "            \n",
    "            times2 = times2.loc[0:times_end]\n",
    "            conti_angle2 = conti_angle2.loc[0:times_end]\n",
    "            \n",
    "            print(\"Graphing block 2 has completed\")\n",
    "            \n",
    "            ##############################Graphing#########################\n",
    "            \n",
    "            #Graph a Scatter Plot otherwize the hover tool hovers to made up points\n",
    "            fig,ax = plt.subplots()\n",
    "            \n",
    "            if graph_style == 'scatter':\n",
    "                ax.scatter(times1,conti_angle1, c = 'k', s = 5)\n",
    "                ax.scatter(times2,conti_angle2, c = 'r', s = 5)\n",
    "            else:\n",
    "                line, = plt.plot(times1,conti_angle1, 'k')\n",
    "                line, = plt.plot(times2,conti_angle2, 'r')\n",
    "                \n",
    "            print('before is running')\n",
    "            #setting up for making vertical lines or indications of bad points (high and low points)\n",
    "            ang_min = min(conti_angle1)\n",
    "            ang_max = max(conti_angle1)\n",
    "            print('after is running')\n",
    "            #find and graph lower bad values\n",
    "            bad_times_down = data_fil_down_bad[\"Time (ms)\"] \n",
    "            ax.vlines([bad_times_down], ang_min, ang_max, linestyles = 'dashed', colors = 'red')\n",
    "\n",
    "            # find and graph upper bad values\n",
    "            bad_times_up = data_fil_up_bad[\"Time (ms)\"] \n",
    "            ax.vlines([bad_times_up], ang_min, ang_max, linestyles = 'dashed', colors = 'black')\n",
    "\n",
    "            # find and graph the invalid bad values\n",
    "            invalid_times = data_back[\"Time (ms)\"]\n",
    "            ax.vlines([invalid_times], ang_min, ang_max, linestyles = 'dashed', colors = 'darkcyan')\n",
    "            \n",
    "            #Hertz Calculation\n",
    "            my_unit = \"Hz\"\n",
    "            og_hz = 1/(time_step*10**(-3))  # calculation of capture period [or frame length] in milisecond to hertz\n",
    "            og_hz_s = str(og_hz) # convert into a string\n",
    "            og_hz_s = og_hz_s + my_unit # create a labeled Hz \n",
    "            \n",
    "            lower_hz = og_hz/bin_size\n",
    "            lower_hz_s = str(lower_hz)\n",
    "            lower_hz_s = lower_hz_s + my_unit\n",
    "            \n",
    "            #Legend\n",
    "            ax.legend([og_hz_s, lower_hz_s,'Lower Sus','Upper Sus'], loc = 'lower right')\n",
    "            \n",
    "            #formatting\n",
    "            plt.rcParams['figure.figsize'] = [13,6]\n",
    "\n",
    "            plt.xlabel('Time (ms)')\n",
    "            plt.ylabel('Angle Accumulation (degrees)')\n",
    "            plt.title('Accumulation of Angle (deg) as a function of Time (ms)')\n",
    "\n",
    "\n",
    "            plt.xlim(0,max(times1))\n",
    "            plt.ylim(ang_min-180,ang_max+180)\n",
    "            ax.set_xticks(np.arange(0, max(times1), 1000))\n",
    "            ax.set_yticks(np.arange(ang_min-180, ang_max+180, 180))\n",
    "            plt.xticks(rotation = -45)\n",
    "            plt.grid()\n",
    "\n",
    "            #hovering attempt 2\n",
    "            #added by Jerry for Matplotlib compatible hovering\n",
    "            mplcursors.cursor(hover=True)\n",
    "        \n",
    "            \n",
    "        \n",
    "        \n",
    "        return data\n",
    "\n",
    "data = DORA(**parameters)\n",
    "\n",
    "\n",
    "# DORA(**parameters)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646bd52b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "origami",
   "language": "python",
   "name": "origami"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
